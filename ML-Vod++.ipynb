{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vodafone Challenge\n",
    "## Scrap notebook\n",
    "- **Separate each test** you make with a markdown cell like this one (press M when the cursor is on a cell but it is not editing). \n",
    "- Put a **small description** on what you are doing and why you do so (like if you manipulate data in a specific way, or apply a particular definition of distance, write the intuition behind. Both for you to remmember later and for team members)\n",
    "- Make sure you are working with the **proper data** i.e. the data (and their transformation) that you with to use are defined before you do the analysis. Bugs could appear if you do not define something and Python retrieves older values for the variables you are using.\n",
    "- **Do not modify df_backup**, always work with a copy [like df = df_backup.copy()]\n",
    "- Add short line of description in the Summary section\n",
    "- For each test, write briefly which value of the parameter tried (like learning rate constant, tried eta0 large (10^-2) not well, smaller (10^-7) seem to work best. Then changed with learning rate adaptivive [which?] and tried ... large (10^-2) worked best).\n",
    "\n",
    "**For the best test, build pipeline: bulleted version of all things done on the dataset until the result. It could be a useful thing to do for each test actually**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **K-means on traffic data**: tested for different k's, both standardized and not. Performs poorly.\n",
    "2. **preprocessing zip-urb** (Abetone, Montoro, Ginosa, Capannori, Vigo di Fassa, Scarpiera e San Piero)\n",
    "3. **Perc imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "### *setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_backup = pd.read_csv('dataset_challenge_v5.TRAINING.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "**DeviceOperatingSystem**: I preferred not to create a specific category for 'windows' because too few observations, however, if the 'other' category reveals to explain well, we can unpack it (in a new dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_clean = df_backup.copy()\n",
    "\n",
    "del df_clean['Unnamed: 0']\n",
    "\n",
    "c = list(df_clean.columns)\n",
    "c[0] = 'ID'\n",
    "df_clean.columns = c\n",
    "\n",
    "df_clean['ZipCode'] = df_clean['ZipCode'].map(lambda x: '%05i' % x, na_action='ignore')\n",
    "\n",
    "traffic_columns = ['File-Transfer', 'Games',\n",
    "       'Instant-Messaging-Applications', 'Mail', 'Music-Streaming',\n",
    "       'Network-Operation', 'P2P-Applications', 'Security',\n",
    "       'Streaming-Applications', 'Terminals', 'Unclassified', 'VoIP',\n",
    "       'Web-Applications']\n",
    "df_clean[traffic_columns]\n",
    "\n",
    "cats = df_clean['CustomerAge'].astype('category').cat.categories\n",
    "d = {cat:(15+10*i)/100 for i,cat in enumerate(cats)}\n",
    "df_clean['NumericAge'] = df_clean['CustomerAge'].map(lambda x: d[x], na_action='ignore')\n",
    "\n",
    "d = {}\n",
    "for elem in df_clean['DeviceOperatingSystem']:\n",
    "    d[elem] = d.get(elem, 0) + 1\n",
    "print(d) #some categories have very few values, group them\n",
    "OS_other = []\n",
    "for key in d:\n",
    "    if d[key] < 10:\n",
    "        OS_other.append(key)\n",
    "        d[key] = 'other'\n",
    "    else:\n",
    "        d[key] = key\n",
    "df_clean['OS_clean'] = df_clean['DeviceOperatingSystem'].map(lambda x: d[x], na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding rural/urban information\n",
    "df_zip_istat = pd.read_csv('databases/database.csv')\n",
    "df_istat_urb = pd.read_csv('databases/it_postal_codes.csv/Foglio 2-Tabella 1.csv', error_bad_lines=False, sep = ';')\n",
    "my_urb_dict = {'Basso' : 0, 'Medio' : 1, 'Elevato' : 2}\n",
    "df_istat_urb['GradoUrbaniz'] = df_istat_urb['GradoUrbaniz'].map(lambda x: my_urb_dict[x], na_action = 'ignore')\n",
    "\n",
    "#check there are no datapoint for which we don't have zip but we've region\n",
    "df_clean['ZipCode'].isnull()\n",
    "df_clean['Region'][df_clean['ZipCode'].isnull()]\n",
    "len(df_clean['Region'][df_clean['ZipCode'].isnull()]) == np.sum(df_clean['Region'][df_clean['ZipCode'].isnull()].isnull())\n",
    "\n",
    "#we need to insert x for multiple cap cities\n",
    "isnan = lambda x: x != x\n",
    "#nan is unique type not equal to itself, so with this lambda function we get True only when the type is NaN\n",
    "\n",
    "for i in range(df_zip_istat.shape[0]):\n",
    "    cap = df_zip_istat.loc[i, 'cap/0']\n",
    "    cap  = '%05d' % cap\n",
    "    if not isnan(df_zip_istat.loc[i,'cap/1']):\n",
    "        if not isnan(df_zip_istat.loc[i,'cap/10']):   \n",
    "            cap = cap[:-2]+'xx'\n",
    "        else:\n",
    "            cap = cap[:-1]+'x'\n",
    "    df_zip_istat.loc[i, 'cap/0'] = cap\n",
    "\n",
    "d_zip_istat = df_zip_istat.set_index('cap/0').to_dict()['codice']\n",
    "d_istat_urb = df_istat_urb.set_index('ISTAT').to_dict()['GradoUrbaniz']\n",
    "\n",
    "mask = df_clean['ZipCode'].isnull()\n",
    "urban_col = np.zeros(df_clean.shape[0])\n",
    "urban_col_masked = urban_col[~ mask]\n",
    "d_zip_istat.update([('51021', 47023),( '83026', 64121),( '74025', 73007),( '55062', 46007),( '38039', 22217),('50037', 48053)])\n",
    "d_istat_urb.update([(22250, 0),( 78157, 1)])\n",
    "\n",
    "c = 0\n",
    "for i in df_clean['ZipCode'][~ mask]:\n",
    "    try:\n",
    "        temp = d_zip_istat[i]\n",
    "        urban_col_masked[c] = d_istat_urb[int(temp)]\n",
    "    except KeyError:\n",
    "        i = '%05d' % int(i)\n",
    "        if i[:-1]+'x' in d_zip_istat:\n",
    "            temp = d_zip_istat[i[:-1]+'x']\n",
    "        elif i[:-2]+'xx' in d_zip_istat:\n",
    "            temp = d_zip_istat[i[:-2]+'xx']\n",
    "        else:\n",
    "            raise()\n",
    "    c += 1\n",
    "    \n",
    "df_clean['Urban'] = df_clean['ZipCode'].copy()\n",
    "df_clean['Urban'][~ mask] = urban_col_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition and useful dependencies\n",
    "Space that collects classes or function definition that come in handy throughtout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class buildTrain():\n",
    "    def __init__(self, X, y, perc=(0.7,0.15,0.15), std=False, pca=0, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        n_data, n_features = X.shape\n",
    "        if not isinstance(perc, tuple) or np.abs(1-sum(perc))>1e-7:\n",
    "            raise Exception('Invalid value for perc', perc)\n",
    "        assert n_data == len(y)\n",
    "        \n",
    "        dopca = pca is None or pca > 0\n",
    "        \n",
    "        #check and remove nan values\n",
    "        temp = X.copy()\n",
    "        temp[y.name] = y.copy()\n",
    "        temp.dropna(axis=0, how='any', inplace=True)\n",
    "        \n",
    "        if temp.shape[0] < n_data:\n",
    "            print('Warning: missing data found and removed. Old input shape: %d, %d, new input shape: %d, %d'\n",
    "                  % (X.shape[0], X.shape[1]+1, *temp.shape))\n",
    "            X = temp\n",
    "            y = temp[y.name]\n",
    "            X.drop(y.name, axis=1, inplace=True)\n",
    "            n_data, _ = X.shape\n",
    "    \n",
    "        assert n_data == len(y)\n",
    "        \n",
    "        perm = np.random.random(n_data)\n",
    "        n_train = int(perc[0]*n_data)\n",
    "        n_valid = int(perc[1]*n_data)\n",
    "        train_mask = perm < perc[0]\n",
    "        valid_mask = ~ train_mask.copy()\n",
    "        valid_mask[~train_mask] = perm[~train_mask] < perc[0] + perc[1]\n",
    "        test_mask = ~ np.logical_or(train_mask, valid_mask)\n",
    "        \n",
    "        train_data = X[train_mask]\n",
    "        train_target = y[train_mask]\n",
    "        valid_data = X[valid_mask]\n",
    "        valid_target = y[valid_mask]\n",
    "        test_data = X[test_mask]\n",
    "        test_target = y[test_mask] \n",
    "        assert (len(train_data)+len(valid_data)+len(test_data)) == n_data\n",
    "        \n",
    "        if std:\n",
    "            mean = train_data.mean(axis=0)\n",
    "            std = train_data.std(axis=0) + 1e-10\n",
    "            train_data = (train_data - mean) / std\n",
    "            valid_data = (valid_data - mean) / std\n",
    "            test_data = (test_data - mean) / std\n",
    "            print('Performed standardization')\n",
    "        \n",
    "        if dopca:\n",
    "            my_pca = PCA(n_components=pca)\n",
    "            my_pca.fit(train_data)\n",
    "            train_data = my_pca.transform(train_data)\n",
    "            valid_data = my_pca.transform(valid_data)\n",
    "            test_data = my_pca.transform(test_data)\n",
    "            print('performed PCA, number of features: %d, explained variance for component:\\n'%(my_pca.n_components_), \n",
    "                  ['%.2f'%i for i in my_pca.explained_variance_ratio_])\n",
    "        \n",
    "        self.Xt = train_data\n",
    "        self.yt = train_target\n",
    "        self.Xv = valid_data\n",
    "        self.yv = valid_target\n",
    "        self.Xts = test_data\n",
    "        self.yts = test_target\n",
    "        \n",
    "    def get_train(self):\n",
    "        return self.Xt, self.yt\n",
    "    \n",
    "    def get_valid(self):\n",
    "        return self.Xv, self.yv\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.Xts, self.yts\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.Xt.shape[0], self.Xv.shape[0], self.Xts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logger():\n",
    "    def __init__(self, verbose = True):\n",
    "        self.v = verbose\n",
    "        self.log_ = []\n",
    "        \n",
    "    def log_it(self, text):\n",
    "        #adds to log record\n",
    "        if not isinstance(text, str):\n",
    "            raise Exception('must pass text to logger')\n",
    "        if self.v:\n",
    "            print(text)\n",
    "        self.log_.append(text)\n",
    "        \n",
    "    def print_out(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            raise Exception('must pass text to logger')\n",
    "        #doesn't add to log record\n",
    "        if self.v:\n",
    "            print(text)\n",
    "        \n",
    "    def show_img(self, array):\n",
    "        if not isinstance(array, np.ndarray):\n",
    "            raise Exception(1)\n",
    "        if self.v:\n",
    "            plt.imshow(array)\n",
    "        \n",
    "    def get_log(self):\n",
    "        return \"\\n\".join(self.log_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_clusters(y, clust_labels, img_threshold=15, v=True):\n",
    "    #checks input\n",
    "    if y.ndim != 1: \n",
    "        raise Exception(2)\n",
    "    if len(y) != len(clust_labels):\n",
    "        raise Exception(4)\n",
    "    \n",
    "    #logger setup\n",
    "    my_log = logger(verbose=v)\n",
    "        \n",
    "    #build histogram of categories (how many point for each cat)\n",
    "    cats = {}\n",
    "    for i in y:\n",
    "        cats[i] = cats.get(i, 0) + 1\n",
    "    n_cats = len(cats)\n",
    "    \n",
    "    #build histogram of clusters (how many point in each cluster)\n",
    "    clusters = {}\n",
    "    for i in clust_labels:\n",
    "        clusters[i] = clusters.get(i, 0) + 1\n",
    "    n_clusters = len(clusters)\n",
    "        \n",
    "    #create mapping from categories to index (to easily store data)\n",
    "    #done because we assume y's values can be different from range(n_categories)\n",
    "    #cat_list useful to quickly go back (header of result matrix)\n",
    "    cat_map = {}\n",
    "    cat_list = []\n",
    "    for i, cat in enumerate(cats):\n",
    "        cat_map[cat] = i\n",
    "        cat_list.append(cat)\n",
    "    \n",
    "    #for each cluster, computes proportion of point belonging to each category\n",
    "    result = np.zeros((n_clusters, n_cats))\n",
    "    tot_per_clust = np.zeros((n_clusters,1), dtype=int)\n",
    "    for i, clust in enumerate(clusters):\n",
    "        labels = y[clust_labels == clust]\n",
    "        tot_per_clust[i] = clusters[clust]\n",
    "        for cat in labels:\n",
    "            result[i,cat_map[cat]] += 1\n",
    "            \n",
    "    #to compute percentage of category points\n",
    "    perc_cat = []\n",
    "    for clust in range(len(result)):\n",
    "        i_max = np.argmax(result[clust,:])\n",
    "        tot = cats[cat_list[i_max]]\n",
    "        perc_cat.append(result[clust, i_max] / tot * 100)\n",
    "        \n",
    "    #express each value as a proportion (normalization)\n",
    "    result = result / tot_per_clust * 100\n",
    "    \n",
    "    #show graphical representation if matrix not too big\n",
    "    if n_cats < img_threshold and n_clusters < img_threshold:\n",
    "        my_log.show_img(result)\n",
    "        \n",
    "    #for each cluster show the category that fits it best\n",
    "    for i,value in enumerate(np.argmax(result, axis=1)):\n",
    "        #frequency of category: number of datapoint of a specific category belonging to that cluster\n",
    "        #over the number of points in the cluster (variety within cluster)\n",
    "        #category clustering: number of datapoint of a specific category belonging to that cluster,\n",
    "        #over the total number of points of that category\n",
    "        my_log.log_it('cluster: %s --> top category: %s, frequency of category (variety within cluster): %.2f%%, category clustering: %.2f%%'\\\n",
    "              % (i, cat_list[value], result[i, value], perc_cat[i]))\n",
    "    score = np.sum(np.max(result, axis=1))/n_clusters\n",
    "    weighted = np.dot(np.max(result, axis=1), np.array(perc_cat))/100\n",
    "    #maybe it's best to weight the score by the category clustering index (see k-means example below)\n",
    "    my_log.log_it(\"Overall score (doesn't consider category clustering): %.2f%%, weighted: %.2f%%\"%(score, weighted))\n",
    "    return weighted, my_log.get_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df, column):\n",
    "    if not isinstance(column, (str, int)):\n",
    "        raise Exception(1)\n",
    "    #returns a copy of the standardized column\n",
    "    c = df[column].copy()\n",
    "    mean = c.mean()\n",
    "    sd = c.std()\n",
    "    return (c - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_std(df, columns):\n",
    "    if not isinstance(columns, str):\n",
    "        if len(columns) == 0:\n",
    "            raise Exception('nto enough columns')\n",
    "    else:\n",
    "        raise Exception('must be an array or list')\n",
    "    #returns a new dataframe with standardized columns\n",
    "    new_df = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        temp = standardize(df, column)\n",
    "        new_df[column] = temp\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__(self):\n",
    "        self.best = [0,0,0]\n",
    "        self.scores = []\n",
    "        \n",
    "    def update(self, score, k):\n",
    "        score, log = score\n",
    "        if score > self.best[0]:\n",
    "            self.best = score, k, log\n",
    "        self.scores.append((k, score))\n",
    "        \n",
    "    def get_result(self):\n",
    "        best = self.best\n",
    "        scores = self.scores\n",
    "        print('best weighted score: %.2f%%, number of clusters: %i' % (best[0], best[1]))\n",
    "        print('log of best: \\n%s' % best[2])\n",
    "        plt.figure()\n",
    "        plt.plot(*zip(*scores),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class interface():\n",
    "    def __init__(self, seed = None, build_seed = None):\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(666766)\n",
    "        self.seed = seed\n",
    "        self.build_seed = build_seed\n",
    "            \n",
    "    def train(self, X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=30, **args):\n",
    "        np.random.seed(self.seed)\n",
    "        data = buildTrain(X, y, percentage, std, pca, seed=self.build_seed)\n",
    "        self._check_balanced(data.get_train()[1], threshold_unbalanced, args)\n",
    "        train_param = (X, y, data, epochs, args)\n",
    "        self._train(*train_param)\n",
    "        if self.unbalanced:\n",
    "            self._unbal_output(data.get_valid())\n",
    "        self.data = data\n",
    "        self.train_param = train_param\n",
    "            \n",
    "    def _check_balanced(self, y, threshold_unbalanced, args):\n",
    "        unbalanced = False\n",
    "        \n",
    "        #check unbalanced dataset\n",
    "        d_cat = {}\n",
    "        clean_y = y[~y.isnull()]\n",
    "        for i in clean_y:\n",
    "            d_cat[i] = d_cat.get(i, 0) + 1\n",
    "        max_cat = 0\n",
    "        max_num = 0\n",
    "        for cat in d_cat:\n",
    "            if d_cat[cat] > max_num:\n",
    "                max_cat = cat\n",
    "                max_num = d_cat[cat] \n",
    "        if max_num / len(clean_y) > threshold_unbalanced:\n",
    "            print('Warning: found unbalanced dataset, training using balanced setting for class_weight')\n",
    "            if 'class_weight' in args and args['class_weight'] is None:\n",
    "                class_weight = {cat: 1/(d_cat[cat]/len(clean_y)) for cat in d_cat}\n",
    "                args['class_weight'] = class_weight\n",
    "                print('Weights used:', {i:float('%.2f'%class_weight[i]) for i in class_weight})\n",
    "            unbalanced = True\n",
    "        self.unbalanced = unbalanced\n",
    "        \n",
    "    def _train(self, X, y, data, epochs, args):\n",
    "        raise Exception('not implemented')\n",
    "            \n",
    "    def _unbal_output(self, valid):\n",
    "        Xv, yv = valid\n",
    "        obj = self.obj\n",
    "        d_cat = {}\n",
    "        for i in yv:\n",
    "            d_cat[i] = d_cat.get(i, 0) + 1\n",
    "        max_cat = 0\n",
    "        max_num = 0\n",
    "        for cat in d_cat:\n",
    "            if d_cat[cat] > max_num:\n",
    "                max_cat = cat\n",
    "                max_num = d_cat[cat]\n",
    "        mask = yv != max_cat\n",
    "        if np.sum(mask) == 0:\n",
    "            raise Exception('No data in smaller part of valid set')\n",
    "        minority_score = obj.score(Xv[mask], yv[mask])\n",
    "        majority_score = obj.score(Xv[~mask], yv[~mask])\n",
    "        print('Score on smaller part (%.2f%%) of validation set (unbalanced case): %.2f' % \n",
    "              (np.sum(mask)/len(yv)*100, minority_score))\n",
    "        print('Score on bigger part (%.2f%%) of validation set (unbalanced case): %.2f' % \n",
    "              (np.sum(~mask)/len(yv)*100, majority_score))\n",
    "        print('Category histogram in validation set:', d_cat)\n",
    "            \n",
    "   \n",
    "        \n",
    "    def test(self, n=10):\n",
    "        best = np.zeros(n)\n",
    "        worse = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            np.random.seed(np.random.randint(10001)*i)\n",
    "            tscores, vscores,_ = self._train(self.train_param)\n",
    "            best[i] = np.max(vscores)\n",
    "            worse[i] = np.min(vscores)\n",
    "        print('average best performance: %.2f%%, standard deviation: %f'%(best.mean(), best.std()))\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(n), worse, color='r', label='worse performances')\n",
    "        plt.plot(np.arange(n), best, color='g', label='best performances')\n",
    "        legend = plt.legend(loc='upper center', shadow=True)\n",
    "        plt.xlabel('samples')\n",
    "        plt.ylabel('test score')\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, X, y, fill_up=False):\n",
    "        obj = self.obj\n",
    "        assert y.shape[0] == X.shape[0]\n",
    "        mask = y.isnull()\n",
    "        to_be_predicted = X[mask]\n",
    "        assert to_be_predicted.shape[0] != 0\n",
    "        prediction = obj.predict(to_be_predicted)\n",
    "        if fill_up:\n",
    "            y[mask] = prediction\n",
    "        return prediction\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.data.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_perc_warm(perc, data, X, y, epochs, eta0, f_eta, v):\n",
    "    \n",
    "    n_features = data.get_train()[0].shape[1]\n",
    "    n_classes = len(data.get_train()[1].unique())\n",
    "    \n",
    "    if n_classes == 1:\n",
    "        raise Exception(1)\n",
    "    if n_classes == 2:\n",
    "        n_classes = 1\n",
    "        \n",
    "    coef = np.random.randn(n_classes, n_features) * 1e-2\n",
    "    intercept = np.random.randn(n_classes) * 1e-2\n",
    "    eta = eta0\n",
    "    \n",
    "    tscores = []\n",
    "    vscores = []\n",
    "    for epoch in range(epochs):\n",
    "        perc.set_params(eta0=eta)\n",
    "        perc.fit(*data.get_train(), coef_init = coef, intercept_init = intercept)\n",
    "        tscore = perc.score(*data.get_train())\n",
    "        vscore = perc.score(*data.get_valid())\n",
    "        if v:\n",
    "            print(\"run=%i tscore=%g vscore=%g\" % (epoch+1, tscore, vscore))\n",
    "        tscores.append(tscore)\n",
    "        vscores.append(vscore)\n",
    "        coef, intercept = perc.coef_, perc.intercept_\n",
    "        eta = f_eta(eta0, epoch)\n",
    "    if v:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(epochs), tscores, np.arange(epochs), vscores)\n",
    "        \n",
    "    return tscores, vscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_perc_cold(perc, data, X, y, max_iter):\n",
    "    \n",
    "    perc.set_params(max_iter=max_iter)\n",
    "    perc.fit(*data.get_train())\n",
    "    tscore = perc.score(*data.get_train())\n",
    "    vscore = perc.score(*data.get_valid())\n",
    "    print(\"tscore=%g vscore=%g\" % (tscore, vscore))\n",
    "        \n",
    "    return tscore, vscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class perc(interface):\n",
    "    \n",
    "    def _train(self, X, y, data, epochs, args):\n",
    "        warm_start = True\n",
    "        learning_rate = args.get('learning_rate', 'optimal')\n",
    "        it_interval = args.pop('it_interval', 100)\n",
    "        power_t = args.get('power_t', 0.5)\n",
    "        #check learning_rate\n",
    "        if learning_rate == 'constant':\n",
    "            f_eta = lambda eta0, epoch: eta0\n",
    "        elif learning_rate == 'invscaling':\n",
    "            f_eta = lambda eta0, epoch: eta0 / ((epoch + 1) * it_interval)**power_t\n",
    "        elif learning_rate == 'optimal':\n",
    "            warm_start = False\n",
    "            f_eta = None\n",
    "        else:\n",
    "            raise Exception('not valid value')                \n",
    "            \n",
    "        #compute max_iter\n",
    "        max_iter = epochs * it_interval\n",
    "        args['max_iter'] = it_interval\n",
    "            \n",
    "        #create multiple perceptron\n",
    "        perc_ = SGDClassifier(**args)\n",
    "\n",
    "        param_warm = (perc_, data, X, y, epochs, args['eta0'], f_eta, True)\n",
    "        param_cold = (perc_, data, X, y, max_iter)\n",
    "        \n",
    "        #perform analysis\n",
    "        if warm_start:\n",
    "            tscores, vscores = train_perc_warm(*param_warm)\n",
    "        else:\n",
    "            tscores, vscores = train_perc_cold(*param_cold)\n",
    "            \n",
    "        self.obj = perc_\n",
    "        return tscores, vscores\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Perceptron interface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_MLP(ml_perc, data, X, y, max_iter= 30, v=True):\n",
    "    \n",
    "    tscores = []\n",
    "    vscores = []\n",
    "    for epoch in range(max_iter):\n",
    "        ml_perc.set_params(max_iter=epoch+1)\n",
    "        ml_perc.fit(*data.get_train())\n",
    "        tscore = ml_perc.score(*data.get_train())\n",
    "        vscore = ml_perc.score(*data.get_valid())\n",
    "        loss = ml_perc.loss_\n",
    "        if v:\n",
    "            print(f\"epoch={epoch} loss={loss} tscore={tscore} vscore={vscore}\")\n",
    "        tscores.append(tscore)\n",
    "        vscores.append(vscore)\n",
    "        ml_perc.set_params(warm_start=True)\n",
    "        \n",
    "    if v:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(max_iter), tscores, np.arange(max_iter), vscores)\n",
    "    \n",
    "    return tscores, vscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(interface):\n",
    "    \n",
    "    def _train(self, X, y, data, epochs, args):             \n",
    "            \n",
    "        #create multiple perceptron\n",
    "        ml_perc_ = MLPClassifier(**args)\n",
    "        \n",
    "        param_warm = (ml_perc_, data, X, y, epochs, True)\n",
    "        \n",
    "        tscores, vscores = train_MLP(*param_warm)\n",
    "        \n",
    "        #save settings\n",
    "        self.obj = ml_perc_\n",
    "        return tscores, vscores\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'MLP interface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LR(log_reg, data, X, y, max_iter= 30, v=True):\n",
    "\n",
    "    tscores = []\n",
    "    vscores = []\n",
    "    for epoch in range(max_iter):\n",
    "        log_reg.set_params(max_iter=epoch+1)\n",
    "        log_reg.fit(*data.get_train())\n",
    "        tscore = log_reg.score(*data.get_train())\n",
    "        vscore = log_reg.score(*data.get_valid())\n",
    "        if v:\n",
    "            print(f\"epoch={epoch} tscore={tscore} vscore={vscore}\")\n",
    "        tscores.append(tscore)\n",
    "        vscores.append(vscore)\n",
    "        log_reg.set_params(warm_start=True)\n",
    "        \n",
    "    if v:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(max_iter), tscores, np.arange(max_iter), vscores)\n",
    "    \n",
    "    return tscores, vscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogReg(interface):\n",
    "    \n",
    "    #penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "    #class_weight=None, random_state=None, solver=’liblinear’, max_iter=100, multi_class=’ovr’, \n",
    "    #verbose=0, warm_start=False, n_jobs=1\n",
    "    #solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’},\n",
    "    #default: ‘liblinear’ Algorithm to use in the optimization problem.\n",
    "    #For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    #For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’\n",
    "    #handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "    #‘newton-cg’, ‘lbfgs’ and ‘sag’ only handle L2 penalty, whereas ‘liblinear’ and ‘saga’ handle L1 penalty.\n",
    "    \n",
    "    #Multiclass option can be either ‘ovr’ or ‘multinomial’. If the option chosen is ‘ovr’, then a binary problem \n",
    "    #is fit for each label. Else the loss minimised is the multinomial loss fit across the entire probability distribution. \n",
    "    #Does not work for liblinear solver.\n",
    "\n",
    "         \n",
    "    def _train(self, X, y, data, epochs, args):            \n",
    "        \n",
    "        #create logistic regression\n",
    "        log_regr_ = LogisticRegression(**args)\n",
    "        \n",
    "        param_warm = (log_regr_, data, X, y, epochs, True)\n",
    "        \n",
    "        tscores, vscores = train_LR(*param_warm)\n",
    "        \n",
    "        #save settings\n",
    "        self.obj = log_regr_\n",
    "        return tscores, vscores\n",
    "    def __str__(self):\n",
    "        return 'Logistic Regression interface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_trees(tree, data, X, y):\n",
    "    \n",
    "    tree.fit(*data.get_train())\n",
    "    tscore = tree.score(*data.get_train())\n",
    "    vscore = tree.score(*data.get_valid())\n",
    "    print(\"tscore=%g vscore=%g\" % (tscore, vscore))\n",
    "        \n",
    "    return tscore, vscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class trees(interface):\n",
    "    \n",
    "    def train(self, X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, tree_type='RF', **args):\n",
    "        np.random.seed(self.seed)\n",
    "        data = buildTrain(X, y, percentage, std, pca, seed=self.build_seed)\n",
    "        self._check_balanced(data.get_train()[1], threshold_unbalanced, args)\n",
    "        train_param = (X, y, data, tree_type, args)\n",
    "        self._train(*train_param)\n",
    "        if self.unbalanced:\n",
    "            self._unbal_output(data.get_valid())\n",
    "        self.data = data\n",
    "        self.tree_type = tree_type\n",
    "        self.train_param = train_param\n",
    "        \n",
    "    def _train(self, X, y, data, tree_type, args):\n",
    "        if tree_type == 'RF':\n",
    "            tree_ = RandomForestClassifier(**args)\n",
    "        elif tree_type == 'DT':\n",
    "            tree_ = tree.DecisionTreeClassifier(**args)\n",
    "        elif tree_type == 'XRF':\n",
    "            tree_ = ExtraTreesClassifier(**args)\n",
    "        else:\n",
    "            raise Exception(1)\n",
    "            \n",
    "        param_warm = (tree_, data, X, y)\n",
    "        tscores, vscores = train_trees(*param_warm)\n",
    "        \n",
    "        #save settings\n",
    "        self.obj = tree_\n",
    "        return tscores, vscores\n",
    "    \n",
    "    def view_tree():\n",
    "        if self.tree_type == 'DT':\n",
    "            dot_data = tree.export_graphviz(self.obj, out_file=None,\n",
    "                             filled=True, rounded=True, special_characters=True)\n",
    "            graph = graphviz.Source(dot_data)  \n",
    "            graph.view()\n",
    "        else:\n",
    "            print(\"Can't show tree for this model\")\n",
    "        \n",
    "    def __str__(self):\n",
    "        if tree_type == 'RF':\n",
    "            return 'Random Forest Interface'\n",
    "        elif tree_type == 'DT':\n",
    "            return 'Decision Tree Interface'\n",
    "        elif tree_type == 'XRF':\n",
    "            return 'Extremely Randomized Trees Interface'\n",
    "        else:\n",
    "            raise Exception(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_sup(*objs):\n",
    "    scores = np.zeros(len(objs))\n",
    "    c = 0\n",
    "    plt.figure()\n",
    "    for obj in objs:\n",
    "        X, y = obj.data.get_test()\n",
    "        if not isinstance(obj, interface):\n",
    "            raise Exception('must pass interface subclass object')\n",
    "        print(X.shape, y.shape)\n",
    "        score = obj.obj.score(X, y)\n",
    "        print(score)\n",
    "        scores[c] = score\n",
    "        print(scores)\n",
    "        c += 1\n",
    "        print(c)\n",
    "        plt.plot(c, score, '.', label=str(obj))\n",
    "    legend = plt.legend(loc=(1.01, 0), shadow=True)\n",
    "    plt.show()\n",
    "    i_max = np.argmax(scores)\n",
    "    print('best is %s with score %.2f' % (str(objs[i_max]), scores[i_max]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. How can we decide which approach to prefer between substituting with the mean of the column and using a trained supervised (with a certain accuracy), in the case of missing values?\n",
    "2. How do we optimize parameters in unbalanced dataset? Because for us we can go over 50% on big and small dataset\n",
    "4. What can we do if dataset unbalanced and we are using MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Train MLP (build interface if needed, should be needed)\n",
    "2. Predict age wrt traffic data for filling in the data\n",
    "3. Predict os wrt traffic data for filling in the data\n",
    "4. Predict urbaniz wrt traffic data for filling in the data\n",
    "5. Predict data allowance wrt traffic data for filling in the data\n",
    "6. Monthly data traffic\n",
    "7. others\n",
    "8. clusteringggg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imputation taken seriously\n",
    "### OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_filled = df_clean.copy()\n",
    "\n",
    "X = df_filled[traffic_columns]\n",
    "y = df_filled['OS_clean']\n",
    "build_seed = 456245\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=100,  loss='log', \n",
    "              penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "              class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=500,\n",
    "             hidden_layer_sizes = (200,), batch_size = 100, learning_rate_init=1e-2, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.01, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_lr.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0.9, threshold_unbalanced=0.6, epochs=100,\n",
    "            penalty=\"l2\", dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "            class_weight=None,  solver=\"newton-cg\", max_iter=100, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sup(my_lr, my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Therefore we use this MLP to predict the rest of the column OS and keep the predictions to imput into our dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os_missing = my_MLP.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urbanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df_filled[traffic_columns]\n",
    "df_filled['Urban'] = df_filled['Urban'].map(lambda x: int(x), na_action = 'ignore')\n",
    "y = df_filled['Urban']\n",
    "build_seed = 4562\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=200,  loss='squared_hinge', \n",
    "              penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "              class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=90,\n",
    "             hidden_layer_sizes = (200,), batch_size = 50, learning_rate_init=1e-4, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.10, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_lr.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=100,\n",
    "            penalty=\"l2\", dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "            class_weight=None,  solver=\"newton-cg\", max_iter=100, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_sup(*my_MLP.get_test(), my_lr, my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urbanization = my_lr.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_numage_to_agecat = {0.85: 2, 0.65: 1, 0.35: 0, 0.75: 1, 0.55: 1, 0.45: 1, 0.25: 0, 0.15: 0}\n",
    "df_filled[\"NumericAge\"] = df_filled[\"NumericAge\"].map(lambda x: dict_numage_to_agecat[x], na_action = 'ignore')\n",
    "X = df_filled[traffic_columns]\n",
    "y = df_filled['NumericAge']\n",
    "build_seed = 456222\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=50,  \n",
    "              loss='log', penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='constant', \n",
    "              eta0=1e-4, class_weight={2.0: 261.4, 1.0: 1.54, 0.0: 4.20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=500,\n",
    "             hidden_layer_sizes = (200,), batch_size = 100, learning_rate_init=1e-2, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.2, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_lr.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=100,\n",
    "            penalty=\"l2\", dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "            class_weight=None,  solver=\"newton-cg\", max_iter=100, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_sup(*my_MLP.get_test(), my_lr, my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pay attention: MLP not weighted\n",
    "num_age = my_perc.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Allowance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the points looks like they're concentrated between 0 and 0.5. To better investigate this, let's look at the density of this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['DataAllowance'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = df_clean['DataAllowance'] > 0.5\n",
    "np.sum(~mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore there are 1575 (over the 1636 not nan) which are below 0.5, so our conjecture was quite good. Given this, our idea is to take into consideration for our imputation just these X's, below 0.5, not using the outliers. We proceed using the above mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_filled[traffic_columns][~mask]\n",
    "df_filled['DataAllowance'] = df_filled['DataAllowance'].map(lambda x: '%.1f'%x, na_action = 'ignore')\n",
    "y = df_filled['DataAllowance'][~mask]\n",
    "\n",
    "build_seed = 4562\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=50,  \n",
    "              loss='log', penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='invscaling', \n",
    "              eta0=1e4, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=50,\n",
    "             hidden_layer_sizes = (400,), batch_size = 100, learning_rate_init=1e-4, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.05, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sup(*my_MLP.get_test(), my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict, we must use the entire X and y, but with our trained MLP just on masked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_filled[traffic_columns]\n",
    "y = df_filled['DataAllowance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = my_MLP.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Data Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_filled[traffic_columns]\n",
    "df_filled['MonthlyDataTraffic'] = df_filled['MonthlyDataTraffic'].map(lambda x: '%.1f'%x, na_action = 'ignore')\n",
    "y = df_filled['MonthlyDataTraffic']\n",
    "build_seed = 4562\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=50,  \n",
    "              loss='log', penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='invscaling', \n",
    "              eta0=1e4, class_weight={'0.2': 15.86, '0.0': 1.6, '0.1': 4.50, '0.5': 1316.0, '0.3': 101.23, '0.4': 188.0, '1.0': 658.0, '0.9': 1316.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=500,\n",
    "             hidden_layer_sizes = (200,), batch_size = 100, learning_rate_init=1e-2, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.01, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sup(*my_MLP.get_test(), my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_traffic = my_MLP.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ARPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_filled[traffic_columns]\n",
    "df_filled['DataArpu'] = df_filled['DataArpu'].map(lambda x: '%.1f'%x, na_action = 'ignore')\n",
    "y = df_filled['DataArpu']\n",
    "build_seed = 4562\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=50,  \n",
    "              loss='log', penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='invscaling', \n",
    "              eta0=1e4, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=100,\n",
    "             hidden_layer_sizes = (200,50), batch_size = 100, learning_rate_init=1e-2, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.01, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_sup(*my_MLP.get_test(), my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_arpu = my_MLP.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Voice Traffic Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_filled[traffic_columns]\n",
    "df_filled['MonthlyVoiceTrafficCount'] = df_filled['MonthlyVoiceTrafficCount'].map(lambda x: '%.1f'%x, na_action = 'ignore')\n",
    "y = df_filled['MonthlyVoiceTrafficCount']\n",
    "build_seed = 4562\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=50,  \n",
    "              loss='log', penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='invscaling', \n",
    "              eta0=1e4, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=(0.70,0.15,0.15), std=False, pca=0, threshold_unbalanced=0.6, epochs=100,\n",
    "             hidden_layer_sizes = (200,50), batch_size = 100, learning_rate_init=1e-2, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.01, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sup(*my_MLP.get_test(), my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voice_traffic_c = my_perc.predict(X,y, fill_up=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_good = df_filled.copy()\n",
    "col_to_del = ['CustomerAge', 'DevicePrice', 'Province', 'Region', 'ZipCode', 'DeviceOperatingSystem']\n",
    "df_good.drop(col_to_del, axis=1, inplace=True)\n",
    "df_good['MonthlySmsTrafficCount'][df_good['MonthlySmsTrafficCount'].isnull()] = df_good['MonthlySmsTrafficCount'].mean()\n",
    "df_good.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = df_good.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
