{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vodafone Challenge\n",
    "## Scrap notebook\n",
    "- **Separate each test** you make with a markdown cell like this one (press M when the cursor is on a cell but it is not editing). \n",
    "- Put a **small description** on what you are doing and why you do so (like if you manipulate data in a specific way, or apply a particular definition of distance, write the intuition behind. Both for you to remmember later and for team members)\n",
    "- Make sure you are working with the **proper data** i.e. the data (and their transformation) that you with to use are defined before you do the analysis. Bugs could appear if you do not define something and Python retrieves older values for the variables you are using.\n",
    "- **Do not modify df_backup**, always work with a copy [like df = df_backup.copy()]\n",
    "- Add short line of description in the Summary section\n",
    "- For each test, write briefly which value of the parameter tried (like learning rate constant, tried eta0 large (10^-2) not well, smaller (10^-7) seem to work best. Then changed with learning rate adaptivive [which?] and tried ... large (10^-2) worked best).\n",
    "\n",
    "**For the best test, build pipeline: bulleted version of all things done on the dataset until the result. It could be a useful thing to do for each test actually**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **K-means on traffic data**: tested for different k's, both standardized and not. Performs poorly.\n",
    "2. **preprocessing zip-urb** (Abetone, Montoro, Ginosa, Capannori, Vigo di Fassa, Scarpiera e San Piero)\n",
    "3. **Perc imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "### *setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(threshold=np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_backup = pd.read_csv('dataset_challenge_v5.TRAINING.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "**DeviceOperatingSystem**: I preferred not to create a specific category for 'windows' because too few observations, however, if the 'other' category reveals to explain well, we can unpack it (in a new dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iOS': 568, nan: 548, 'Android': 858, 'Windows Mobile': 6, 'Proprietary': 5, 'Windows Phone': 7, 'BlackBerry OS': 1, 'Firefox': 1, 'Symbian^3': 1, 'BREW': 1, 'Series 40': 2, 'BB10': 1, 'VRTXmc': 1}\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_backup.copy()\n",
    "\n",
    "del df_clean['Unnamed: 0']\n",
    "\n",
    "c = list(df_clean.columns)\n",
    "c[0] = 'ID'\n",
    "df_clean.columns = c\n",
    "\n",
    "df_clean['ZipCode'] = df_clean['ZipCode'].map(lambda x: '%05i' % x, na_action='ignore')\n",
    "\n",
    "traffic_columns = ['File-Transfer', 'Games',\n",
    "       'Instant-Messaging-Applications', 'Mail', 'Music-Streaming',\n",
    "       'Network-Operation', 'P2P-Applications', 'Security',\n",
    "       'Streaming-Applications', 'Terminals', 'Unclassified', 'VoIP',\n",
    "       'Web-Applications']\n",
    "df_clean[traffic_columns]\n",
    "\n",
    "cats = df_clean['CustomerAge'].astype('category').cat.categories\n",
    "d = {cat:(15+10*i)/100 for i,cat in enumerate(cats)}\n",
    "df_clean['NumericAge'] = df_clean['CustomerAge'].map(lambda x: d[x], na_action='ignore')\n",
    "\n",
    "d = {}\n",
    "for elem in df_clean['DeviceOperatingSystem']:\n",
    "    d[elem] = d.get(elem, 0) + 1\n",
    "print(d) #some categories have very few values, group them\n",
    "OS_other = []\n",
    "for key in d:\n",
    "    if d[key] < 10:\n",
    "        OS_other.append(key)\n",
    "        d[key] = 'other'\n",
    "    else:\n",
    "        d[key] = key\n",
    "df_clean['OS_clean'] = df_clean['DeviceOperatingSystem'].map(lambda x: d[x], na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding rural/urban information\n",
    "df_zip_istat = pd.read_csv('databases/database.csv')\n",
    "df_istat_urb = pd.read_csv('databases/it_postal_codes.csv/Foglio 2-Tabella 1.csv', error_bad_lines=False, sep = ';')\n",
    "my_urb_dict = {'Basso' : 0, 'Medio' : 1, 'Elevato' : 2}\n",
    "df_istat_urb['GradoUrbaniz'] = df_istat_urb['GradoUrbaniz'].map(lambda x: my_urb_dict[x], na_action = 'ignore')\n",
    "\n",
    "#check there are no datapoint for which we don't have zip but we've region\n",
    "df_clean['ZipCode'].isnull()\n",
    "df_clean['Region'][df_clean['ZipCode'].isnull()]\n",
    "len(df_clean['Region'][df_clean['ZipCode'].isnull()]) == np.sum(df_clean['Region'][df_clean['ZipCode'].isnull()].isnull())\n",
    "\n",
    "#we need to insert x for multiple cap cities\n",
    "isnan = lambda x: x != x\n",
    "#nan is unique type not equal to itself, so with this lambda function we get True only when the type is NaN\n",
    "\n",
    "for i in range(df_zip_istat.shape[0]):\n",
    "    cap = df_zip_istat.loc[i, 'cap/0']\n",
    "    cap  = '%05d' % cap\n",
    "    if not isnan(df_zip_istat.loc[i,'cap/1']):\n",
    "        if not isnan(df_zip_istat.loc[i,'cap/10']):   \n",
    "            cap = cap[:-2]+'xx'\n",
    "        else:\n",
    "            cap = cap[:-1]+'x'\n",
    "    df_zip_istat.loc[i, 'cap/0'] = cap\n",
    "\n",
    "d_zip_istat = df_zip_istat.set_index('cap/0').to_dict()['codice']\n",
    "d_istat_urb = df_istat_urb.set_index('ISTAT').to_dict()['GradoUrbaniz']\n",
    "\n",
    "mask = df_clean['ZipCode'].isnull()\n",
    "urban_col = np.zeros(df_clean.shape[0])\n",
    "urban_col_masked = urban_col[~ mask]\n",
    "d_zip_istat.update([('51021', 47023),( '83026', 64121),( '74025', 73007),( '55062', 46007),( '38039', 22217),('50037', 48053)])\n",
    "d_istat_urb.update([(22250, 0),( 78157, 1)])\n",
    "\n",
    "c = 0\n",
    "for i in df_clean['ZipCode'][~ mask]:\n",
    "    try:\n",
    "        temp = d_zip_istat[i]\n",
    "        urban_col_masked[c] = d_istat_urb[int(temp)]\n",
    "    except KeyError:\n",
    "        i = '%05d' % int(i)\n",
    "        if i[:-1]+'x' in d_zip_istat:\n",
    "            temp = d_zip_istat[i[:-1]+'x']\n",
    "        elif i[:-2]+'xx' in d_zip_istat:\n",
    "            temp = d_zip_istat[i[:-2]+'xx']\n",
    "        else:\n",
    "            raise()\n",
    "    c += 1\n",
    "    \n",
    "df_clean['Urban'] = df_clean['ZipCode'].copy()\n",
    "df_clean['Urban'][~ mask] = urban_col_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition and useful dependencies\n",
    "Space that collects classes or function definition that come in handy throughtout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class buildTrain():\n",
    "    def __init__(self, X, y, perc=0.8, std=False, pca=0, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        n_data, n_features = X.shape\n",
    "        assert n_data == len(y)\n",
    "        \n",
    "        dopca = pca is None or pca > 0\n",
    "        \n",
    "        #check and remove nan values\n",
    "        temp = X.copy()\n",
    "        temp[y.name] = y.copy()\n",
    "        temp.dropna(axis=0, how='any', inplace=True)\n",
    "        \n",
    "        if temp.shape[0] < n_data:\n",
    "            print('Warning: missing data found and removed. Old input shape: %d, %d, new input shape: %d, %d'\n",
    "                  % (X.shape[0], X.shape[1]+1, *temp.shape))\n",
    "            X = temp\n",
    "            y = temp[y.name]\n",
    "            X.drop(y.name, axis=1, inplace=True)\n",
    "            n_data, _ = X.shape\n",
    "    \n",
    "        assert n_data == len(y)\n",
    "        \n",
    "        perm = np.random.random(n_data)\n",
    "        train_mask = perm < perc\n",
    "        valid_mask = ~ train_mask\n",
    "        \n",
    "        train_data = X[train_mask]\n",
    "        train_target = y[train_mask]\n",
    "        valid_data = X[valid_mask]\n",
    "        valid_target = y[valid_mask]\n",
    "        assert (len(train_data)+len(valid_data)) == n_data\n",
    "        \n",
    "        if std:\n",
    "            mean = train_data.mean(axis=0)\n",
    "            std = train_data.std(axis=0) + 1e-10\n",
    "            train_data = (train_data - mean) / std\n",
    "            valid_data = (valid_data - mean) / std\n",
    "            print('Performed standardization')\n",
    "        \n",
    "        if dopca:\n",
    "            my_pca = PCA(n_components=pca)\n",
    "            my_pca.fit(train_data)\n",
    "            train_data = my_pca.transform(train_data)\n",
    "            valid_data = my_pca.transform(valid_data)\n",
    "            print('performed PCA, number of features: %d, explained variance for component:\\n'%(my_pca.n_components_), \n",
    "                  ['%.2f'%i for i in my_pca.explained_variance_ratio_])\n",
    "        \n",
    "        self.Xt = train_data\n",
    "        self.yt = train_target\n",
    "        self.Xv = valid_data\n",
    "        self.yv = valid_target\n",
    "        \n",
    "    def get_train(self):\n",
    "        return self.Xt, self.yt\n",
    "    \n",
    "    def get_valid(self):\n",
    "        return self.Xv, self.yv\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.Xt.shape[0], self.Xv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class logger():\n",
    "    def __init__(self, verbose = True):\n",
    "        self.v = verbose\n",
    "        self.log_ = []\n",
    "        \n",
    "    def log_it(self, text):\n",
    "        #adds to log record\n",
    "        if not isinstance(text, str):\n",
    "            raise Exception('must pass text to logger')\n",
    "        if self.v:\n",
    "            print(text)\n",
    "        self.log_.append(text)\n",
    "        \n",
    "    def print_out(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            raise Exception('must pass text to logger')\n",
    "        #doesn't add to log record\n",
    "        if self.v:\n",
    "            print(text)\n",
    "        \n",
    "    def show_img(self, array):\n",
    "        if not isinstance(array, np.ndarray):\n",
    "            raise Exception(1)\n",
    "        if self.v:\n",
    "            plt.imshow(array)\n",
    "        \n",
    "    def get_log(self):\n",
    "        return \"\\n\".join(self.log_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_clusters(y, clust_labels, img_threshold=15, v=True):\n",
    "    #checks input\n",
    "    if y.ndim != 1: \n",
    "        raise Exception(2)\n",
    "    if len(y) != len(clust_labels):\n",
    "        raise Exception(4)\n",
    "    \n",
    "    #logger setup\n",
    "    my_log = logger(verbose=v)\n",
    "        \n",
    "    #build histogram of categories (how many point for each cat)\n",
    "    cats = {}\n",
    "    for i in y:\n",
    "        cats[i] = cats.get(i, 0) + 1\n",
    "    n_cats = len(cats)\n",
    "    \n",
    "    #build histogram of clusters (how many point in each cluster)\n",
    "    clusters = {}\n",
    "    for i in clust_labels:\n",
    "        clusters[i] = clusters.get(i, 0) + 1\n",
    "    n_clusters = len(clusters)\n",
    "        \n",
    "    #create mapping from categories to index (to easily store data)\n",
    "    #done because we assume y's values can be different from range(n_categories)\n",
    "    #cat_list useful to quickly go back (header of result matrix)\n",
    "    cat_map = {}\n",
    "    cat_list = []\n",
    "    for i, cat in enumerate(cats):\n",
    "        cat_map[cat] = i\n",
    "        cat_list.append(cat)\n",
    "    \n",
    "    #for each cluster, computes proportion of point belonging to each category\n",
    "    result = np.zeros((n_clusters, n_cats))\n",
    "    tot_per_clust = np.zeros((n_clusters,1), dtype=int)\n",
    "    for i, clust in enumerate(clusters):\n",
    "        labels = y[clust_labels == clust]\n",
    "        tot_per_clust[i] = clusters[clust]\n",
    "        for cat in labels:\n",
    "            result[i,cat_map[cat]] += 1\n",
    "            \n",
    "    #to compute percentage of category points\n",
    "    perc_cat = []\n",
    "    for clust in range(len(result)):\n",
    "        i_max = np.argmax(result[clust,:])\n",
    "        tot = cats[cat_list[i_max]]\n",
    "        perc_cat.append(result[clust, i_max] / tot * 100)\n",
    "        \n",
    "    #express each value as a proportion (normalization)\n",
    "    result = result / tot_per_clust * 100\n",
    "    \n",
    "    #show graphical representation if matrix not too big\n",
    "    if n_cats < img_threshold and n_clusters < img_threshold:\n",
    "        my_log.show_img(result)\n",
    "        \n",
    "    #for each cluster show the category that fits it best\n",
    "    for i,value in enumerate(np.argmax(result, axis=1)):\n",
    "        #frequency of category: number of datapoint of a specific category belonging to that cluster\n",
    "        #over the number of points in the cluster (variety within cluster)\n",
    "        #category clustering: number of datapoint of a specific category belonging to that cluster,\n",
    "        #over the total number of points of that category\n",
    "        my_log.log_it('cluster: %s --> top category: %s, frequency of category (variety within cluster): %.2f%%, category clustering: %.2f%%'\\\n",
    "              % (i, cat_list[value], result[i, value], perc_cat[i]))\n",
    "    score = np.sum(np.max(result, axis=1))/n_clusters\n",
    "    weighted = np.dot(np.max(result, axis=1), np.array(perc_cat))/100\n",
    "    #maybe it's best to weight the score by the category clustering index (see k-means example below)\n",
    "    my_log.log_it(\"Overall score (doesn't consider category clustering): %.2f%%, weighted: %.2f%%\"%(score, weighted))\n",
    "    return weighted, my_log.get_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df, column):\n",
    "    if not isinstance(column, (str, int)):\n",
    "        raise Exception(1)\n",
    "    #returns a copy of the standardized column\n",
    "    c = df[column].copy()\n",
    "    mean = c.mean()\n",
    "    sd = c.std()\n",
    "    return (c - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_std(df, columns):\n",
    "    if not isinstance(columns, str):\n",
    "        if len(columns) == 0:\n",
    "            raise Exception('nto enough columns')\n",
    "    else:\n",
    "        raise Exception('must be an array or list')\n",
    "    #returns a new dataframe with standardized columns\n",
    "    new_df = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        temp = standardize(df, column)\n",
    "        new_df[column] = temp\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __init__(self):\n",
    "        self.best = [0,0,0]\n",
    "        self.scores = []\n",
    "        \n",
    "    def update(self, score, k):\n",
    "        score, log = score\n",
    "        if score > self.best[0]:\n",
    "            self.best = score, k, log\n",
    "        self.scores.append((k, score))\n",
    "        \n",
    "    def get_result(self):\n",
    "        best = self.best\n",
    "        scores = self.scores\n",
    "        print('best weighted score: %.2f%%, number of clusters: %i' % (best[0], best[1]))\n",
    "        print('log of best: \\n%s' % best[2])\n",
    "        plt.figure()\n",
    "        plt.plot(*zip(*scores),'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class interface():\n",
    "    def __init__(self, seed = None, build_seed = None):\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(666766)\n",
    "        self.seed = seed\n",
    "        self.build_seed = build_seed\n",
    "            \n",
    "    def train(self, X, y, percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=30, **args):\n",
    "        np.random.seed(self.seed)\n",
    "        self._check_balanced(y, threshold_unbalanced, args)\n",
    "        _,_, valid = self._train(X, y, percentage, std, pca, epochs, args)\n",
    "        if self.unbalanced:\n",
    "            self._unbal_output(valid)\n",
    "        self.train_param = (X, y, percentage, std, pca, epochs, args)\n",
    "            \n",
    "    def _check_balanced(self, y, threshold_unbalanced, args):\n",
    "        unbalanced = False\n",
    "        \n",
    "        #check unbalanced dataset\n",
    "        d_cat = {}\n",
    "        clean_y = y[~y.isnull()]\n",
    "        for i in clean_y:\n",
    "            d_cat[i] = d_cat.get(i, 0) + 1\n",
    "        max_cat = 0\n",
    "        max_num = 0\n",
    "        for cat in d_cat:\n",
    "            if d_cat[cat] > max_num:\n",
    "                max_cat = cat\n",
    "                max_num = d_cat[cat]\n",
    "                    \n",
    "        if max_num / len(clean_y) > threshold_unbalanced:\n",
    "            print('Warning: found unbalanced dataset, training using balanced setting for class_weight')\n",
    "            if 'class_weight' in args and args['class_weight'] is None:\n",
    "                class_weight = {cat:1/(d_cat[cat]/len(clean_y)) for cat in d_cat}\n",
    "                args['class_weight'] = class_weight\n",
    "                print('Weights used:', {i:float('%.2f'%d_cat[i]) for i in class_weight})\n",
    "            unbalanced = True\n",
    "        self.unbalanced = unbalanced\n",
    "        \n",
    "    def _train(self, X, y, percentage, std, pca, epochs, args):\n",
    "        raise Exception('not implemented')\n",
    "            \n",
    "    def _unbal_output(self, valid):\n",
    "        Xv, yv = valid\n",
    "        obj = self.obj\n",
    "        d_cat = {}\n",
    "        for i in yv:\n",
    "            d_cat[i] = d_cat.get(i, 0) + 1\n",
    "        max_cat = 0\n",
    "        max_num = 0\n",
    "        for cat in d_cat:\n",
    "            if d_cat[cat] > max_num:\n",
    "                max_cat = cat\n",
    "                max_num = d_cat[cat]\n",
    "        mask = yv != max_cat\n",
    "        if np.sum(mask) == 0:\n",
    "            raise Exception('No data in smaller part of valid set')\n",
    "        minority_score = obj.score(Xv[mask], yv[mask])\n",
    "        majority_score = obj.score(Xv[~mask], yv[~mask])\n",
    "        print('Score on smaller part (%.2f%%) of validation set (unbalanced case): %.2f' % \n",
    "              (np.sum(mask)/len(yv)*100, minority_score))\n",
    "        print('Score on bigger part (%.2f%%) of validation set (unbalanced case): %.2f' % \n",
    "              (np.sum(~mask)/len(yv)*100, majority_score))\n",
    "        print('Category histogram in validation set:', d_cat)\n",
    "            \n",
    "   \n",
    "        \n",
    "    def test(self, n=10):\n",
    "        best = np.zeros(n)\n",
    "        worse = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            np.random.seed(np.random.randint(10001)*i)\n",
    "            tscores, vscores,_ = self._train(self.train_param)\n",
    "            best[i] = np.max(vscores)\n",
    "            worse[i] = np.min(vscores)\n",
    "        print('average best performance: %.2f%%, standard deviation: %f'%(best.mean(), best.std()))\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(n), worse, color='r', label='worse performances')\n",
    "        plt.plot(np.arange(n), best, color='g', label='best performances')\n",
    "        legend = plt.legend(loc='upper center', shadow=True)\n",
    "        plt.xlabel('samples')\n",
    "        plt.ylabel('test score')\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, X, y):\n",
    "        obj = self.obj\n",
    "        mask = y.isnull()\n",
    "        to_be_predicted = X[mask]\n",
    "        assert y.shape[0] == X.shape[0]\n",
    "        assert to_be_predicted.shape[0] != 0\n",
    "        return obj.predict(to_be_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_perc_warm(perc, X, y, epochs, eta0, percentage, f_eta, std, pca, v, build_seed):\n",
    "    \n",
    "    data = buildTrain(X, y, percentage, std, pca, seed=build_seed)\n",
    "    \n",
    "    n_features = data.get_train()[0].shape[1]\n",
    "    n_classes = len(data.get_train()[1].unique())\n",
    "    \n",
    "    if n_classes == 1:\n",
    "        raise Exception(1)\n",
    "    if n_classes == 2:\n",
    "        n_classes = 1\n",
    "        \n",
    "    coef = np.random.randn(n_classes, n_features) * 1e-2\n",
    "    intercept = np.random.randn(n_classes) * 1e-2\n",
    "    eta = eta0\n",
    "    \n",
    "    tscores = []\n",
    "    vscores = []\n",
    "    for epoch in range(epochs):\n",
    "        perc.set_params(eta0=eta)\n",
    "        perc.fit(*data.get_train(), coef_init = coef, intercept_init = intercept)\n",
    "        tscore = perc.score(*data.get_train())\n",
    "        vscore = perc.score(*data.get_valid())\n",
    "        if v:\n",
    "            print(\"run=%i tscore=%g vscore=%g\" % (epoch+1, tscore, vscore))\n",
    "        tscores.append(tscore)\n",
    "        vscores.append(vscore)\n",
    "        coef, intercept = perc.coef_, perc.intercept_\n",
    "        eta = f_eta(eta0, epoch)\n",
    "    if v:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(epochs), tscores, np.arange(epochs), vscores)\n",
    "        \n",
    "    return tscores, vscores, data.get_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_perc_cold(perc, X, y, percentage, max_iter, std, pca, build_seed):\n",
    "    data = buildTrain(X, y, percentage, std, pca, seed=build_seed)\n",
    "    \n",
    "    perc.set_params(max_iter=max_iter)\n",
    "    perc.fit(*data.get_train())\n",
    "    tscore = perc.score(*data.get_train())\n",
    "    vscore = perc.score(*data.get_valid())\n",
    "    print(\"tscore=%g vscore=%g\" % (tscore, vscore))\n",
    "        \n",
    "    return tscore, vscore, data.get_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class perc(interface):\n",
    "    \n",
    "    def _train(self, X, y, percentage, std, pca, epochs, args):\n",
    "        warm_start = True\n",
    "        learning_rate = args.get('learning_rate', 'optimal')\n",
    "        it_interval = args.pop('it_interval', 100)\n",
    "        power_t = args.get('power_t', 0.5)\n",
    "        #check learning_rate\n",
    "        if learning_rate == 'constant':\n",
    "            f_eta = lambda eta0, epoch: eta0\n",
    "        elif learning_rate == 'invscaling':\n",
    "            f_eta = lambda eta0, epoch: eta0 / ((epoch + 1) * it_interval)**power_t\n",
    "        elif learning_rate == 'optimal':\n",
    "            warm_start = False\n",
    "            f_eta = None\n",
    "        else:\n",
    "            raise Exception('not valid value')                \n",
    "            \n",
    "        #compute max_iter\n",
    "        max_iter = epochs * it_interval\n",
    "        args['max_iter'] = it_interval\n",
    "            \n",
    "        #create multiple perceptron\n",
    "        perc_ = SGDClassifier(**args)\n",
    "\n",
    "        param_warm = (perc_, X, y, epochs, args['eta0'], percentage, f_eta, std, pca, True, self.build_seed)\n",
    "        param_cold = (perc_, X, y, percentage, max_iter, std, pca, self.build_seed)\n",
    "        \n",
    "        #perform analysis\n",
    "        if warm_start:\n",
    "            tscores, vscores, valid = train_perc_warm(*param_warm)\n",
    "        else:\n",
    "            tscores, vscores, valid = train_perc_cold(*param_cold)\n",
    "            \n",
    "        self.obj = perc_\n",
    "        return tscores, vscores, valid\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Perceptron interface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_MLP(ml_perc, X, y, percentage=0.8, max_iter= 30, std=False, pca=0, v=True, build_seed=None):\n",
    "    \n",
    "    data = buildTrain(X, y, percentage, std, pca, seed=build_seed)\n",
    "    \n",
    "    tscores = []\n",
    "    vscores = []\n",
    "    for epoch in range(max_iter):\n",
    "        ml_perc.set_params(max_iter=epoch+1)\n",
    "        ml_perc.fit(*data.get_train())\n",
    "        tscore = ml_perc.score(*data.get_train())\n",
    "        vscore = ml_perc.score(*data.get_valid())\n",
    "        loss = ml_perc.loss_\n",
    "        if v:\n",
    "            print(f\"epoch={epoch} loss={loss} tscore={tscore} vscore={vscore}\")\n",
    "        tscores.append(tscore)\n",
    "        vscores.append(vscore)\n",
    "        ml_perc.set_params(warm_start=True)\n",
    "        \n",
    "    if v:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(max_iter), tscores, np.arange(max_iter), vscores)\n",
    "    \n",
    "    return tscores, vscores, data.get_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(interface):\n",
    "    \n",
    "    def _train(self, X, y, percentage, std, pca, epochs, args):             \n",
    "            \n",
    "        #create multiple perceptron\n",
    "        ml_perc_ = MLPClassifier(**args)\n",
    "        \n",
    "        param_warm = (ml_perc_, X, y, percentage, epochs, std, pca, True, self.build_seed)\n",
    "        \n",
    "        tscores, vscores, valid = train_MLP(*param_warm)\n",
    "        \n",
    "        #save settings\n",
    "        self.obj = ml_perc_\n",
    "        return tscores, vscores, valid\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'MLP interface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LR(log_reg, X, y, percentage=0.8, max_iter= 30, std=False, pca=0, v=True, build_seed=None):\n",
    "    \n",
    "    data = buildTrain(X, y, percentage, std, pca, seed=build_seed)\n",
    "\n",
    "    tscores = []\n",
    "    vscores = []\n",
    "    for epoch in range(max_iter):\n",
    "        log_reg.set_params(max_iter=epoch+1)\n",
    "        log_reg.fit(*data.get_train())\n",
    "        tscore = log_reg.score(*data.get_train())\n",
    "        vscore = log_reg.score(*data.get_valid())\n",
    "        if v:\n",
    "            print(f\"epoch={epoch} tscore={tscore} vscore={vscore}\")\n",
    "        tscores.append(tscore)\n",
    "        vscores.append(vscore)\n",
    "        log_reg.set_params(warm_start=True)\n",
    "        \n",
    "    if v:\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(max_iter), tscores, np.arange(max_iter), vscores)\n",
    "    \n",
    "    return tscores, vscores, data.get_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogReg(interface):\n",
    "    \n",
    "    #penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "    #class_weight=None, random_state=None, solver=’liblinear’, max_iter=100, multi_class=’ovr’, \n",
    "    #verbose=0, warm_start=False, n_jobs=1\n",
    "    #solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’},\n",
    "    #default: ‘liblinear’ Algorithm to use in the optimization problem.\n",
    "    #For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "    #For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’\n",
    "    #handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "    #‘newton-cg’, ‘lbfgs’ and ‘sag’ only handle L2 penalty, whereas ‘liblinear’ and ‘saga’ handle L1 penalty.\n",
    "    \n",
    "    #Multiclass option can be either ‘ovr’ or ‘multinomial’. If the option chosen is ‘ovr’, then a binary problem \n",
    "    #is fit for each label. Else the loss minimised is the multinomial loss fit across the entire probability distribution. \n",
    "    #Does not work for liblinear solver.\n",
    "\n",
    "         \n",
    "    def _train(self, X, y, percentage, std, pca, epochs, args):            \n",
    "        \n",
    "        #create logistic regression\n",
    "        log_regr_ = LogisticRegression(**args)\n",
    "        \n",
    "        param_warm = (log_regr_, X, y, percentage, epochs, std, pca, True, self.build_seed)\n",
    "        \n",
    "        tscores, vscores, valid = train_LR(*param_warm)\n",
    "        \n",
    "        #save settings\n",
    "        self.obj = log_regr_\n",
    "        return tscores, vscores, valid\n",
    "    def __str__(self):\n",
    "        return 'Logistic Regression interface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_sup(X, y, *objs):\n",
    "    assert X.shape[0] == len(y)\n",
    "    scores = np.zeros(len(objs))\n",
    "    c = 0\n",
    "    plt.figure()\n",
    "    for obj in objs:\n",
    "        if not isinstance(obj, interface):\n",
    "            raise Exception('must pass interface subclass object')\n",
    "        score = obj.obj.score(X, y)\n",
    "        scores[c] = score\n",
    "        c += 1\n",
    "        plt.plot(c, score, '.', label=str(obj))\n",
    "    legend = plt.legend(loc=(1.01, 0), shadow=True)\n",
    "    plt.show()\n",
    "    i_max = np.argmax(scores)\n",
    "    print('best is %s with score %.2f' % (str(objs[i_max]), scores[i_max]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. How can we decide which approach to prefer between substituting with the mean of the column and using a trained supervised (with a certain accuracy), in the case of missing values?\n",
    "2. How do we optimize parameters in unbalanced dataset? Because for us we can go over 50% on big and small dataset\n",
    "4. What can we do if dataset unbalanced and we are using MLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Train MLP (build interface if needed, should be needed)\n",
    "2. Predict age wrt traffic data for filling in the data\n",
    "3. Predict os wrt traffic data for filling in the data\n",
    "4. Predict urbaniz wrt traffic data for filling in the data\n",
    "5. Predict data allowance wrt traffic data for filling in the data\n",
    "6. Monthly data traffic\n",
    "7. others\n",
    "8. clusteringggg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means on traffic\n",
    "Just an exploratory study, let's see what we get..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = df_clean[traffic_columns]\n",
    "y = df_clean['Product']\n",
    "\n",
    "km = KMeans(n_clusters=6, init='k-means++', n_init=10, n_jobs=4)\n",
    "km.fit(X)\n",
    "score = check_clusters(y=y, clust_labels=km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we try the same but with standardized columns, see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_std = batch_std(df_clean, traffic_columns)\n",
    "y = df_clean['Product']\n",
    "\n",
    "km = KMeans(n_clusters=6, init='k-means++', n_init=10, n_jobs=4)\n",
    "km.fit(X_std)\n",
    "score = check_clusters(y=y, clust_labels=km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to have improved. Still the clusters seem to separate pretty poorly. Let's see the optimal value of k based on our previous score (using standardized data which seem to make more sense). We set the same seed each time so that the results are comparable and not influenced by different initial centroid allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_test = test()\n",
    "\n",
    "np.random.seed(23453)\n",
    "X_std = batch_std(df_clean, traffic_columns)\n",
    "y = df_clean['Product']\n",
    "\n",
    "for k in range(2, 10):\n",
    "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, n_jobs=4)\n",
    "    km.fit(X_std)\n",
    "    \n",
    "    score= check_clusters(y=y, clust_labels=km.labels_, v=False)\n",
    "    my_test.update(score, k)\n",
    "        \n",
    "my_test.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering on traffic data\n",
    "Same approach as for k-means, test difference between standardized and not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "my_test = test()\n",
    "X_std = batch_std(df_clean, traffic_columns)\n",
    "y = df_clean['Product']\n",
    "\n",
    "for k in range(2, 8):\n",
    "    clust = AgglomerativeClustering(n_clusters=k, linkage='ward', affinity='euclidean')\n",
    "    clust.fit(X_std)\n",
    "    score = check_clusters(y=y, clust_labels=clust.labels_, v=False)\n",
    "    my_test.update(score, k)\n",
    "\n",
    "my_test.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try complete linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "my_test = test()\n",
    "X_std = batch_std(df_clean, traffic_columns)\n",
    "y = df_clean['Product']\n",
    "\n",
    "for k in range(2, 8):\n",
    "    clust = AgglomerativeClustering(n_clusters=k, linkage='complete', affinity='euclidean')\n",
    "    clust.fit(X_std)\n",
    "    score = check_clusters(y=y, clust_labels=clust.labels_, v=False)\n",
    "    my_test.update(score, k)\n",
    "\n",
    "my_test.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron (imputation of age data with traffic data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we try to build a Perceptron to complete the age column keeping all the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "#df.dropna(axis=0, how='any', subset=['NumericAge'], inplace=True)\n",
    "\n",
    "#merge some age ranges together\n",
    "#dict_numage_to_agecat = {i : int(100*i//40) for i in df[\"NumericAge\"].unique()}\n",
    "dict_numage_to_agecat = {0.85: 2, 0.65: 1, 0.35: 0, 0.75: 1, 0.55: 1, 0.45: 1, 0.25: 0, 0.15: 0}\n",
    "print(dict_numage_to_agecat)\n",
    "df[\"NumericAge\"] = df[\"NumericAge\"].map(lambda x: dict_numage_to_agecat[x], na_action = 'ignore')\n",
    "X = df[traffic_columns]\n",
    "y = df['NumericAge']\n",
    "my_perc = perc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=100,  loss='log', penalty='none', alpha=1e-6,\n",
    "          power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "          class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_perc.predict(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "#df.dropna(axis=0, how='any', subset=['Urban'], inplace=True)\n",
    "\n",
    "#merge some age ranges together\n",
    "#dict_numage_to_agecat = {i : int(100*i//40) for i in df[\"NumericAge\"].unique()}\n",
    "X = df[traffic_columns]\n",
    "#unbalanced?\n",
    "#np.bincount(y[~np.isnan(y)].astype(int))\n",
    "y = df['Urban'].map(lambda x: int(x), na_action = 'ignore')\n",
    "my_perc = perc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=100,  loss='log', penalty='none', alpha=1e-6,\n",
    "          power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "          class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df[traffic_columns]\n",
    "y = df['OS_clean']\n",
    "my_perc = perc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=100,  loss='log', penalty='none', alpha=1e-6,\n",
    "          power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "          class_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df[traffic_columns]\n",
    "\n",
    "y = df['DataAllowance'].map(lambda x: '%.1f'%x, na_action = 'ignore')\n",
    "print(y.unique())\n",
    "my_perc = perc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_perc.train(X, y, percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=100,  loss='log', penalty='none', alpha=1e-6,\n",
    "          power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "          class_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df[traffic_columns]\n",
    "y = df['OS_clean']\n",
    "my_MLP = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.train(X, y, percentage=0.8, std=True, pca=None, threshold_unbalanced=0.6, epochs=50,\n",
    "             hidden_layer_sizes = (200,), batch_size = 100, learning_rate_init=1e-1, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.0, nesterovs_momentum = False,\n",
    "             alpha = 0.0, tol = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_MLP.predict(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = df_clean['OS_clean'].copy()\n",
    "d = dict()\n",
    "for i in a:\n",
    "    d[i] = d.get(i, 0) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df[traffic_columns]\n",
    "y = df['OS_clean']\n",
    "my_lr = LogReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_lr.train(X, y, percentage=0.8, std=True, pca=None, threshold_unbalanced=0.6, epochs=50,\n",
    "            penalty=\"l2\", dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "            class_weight=None,  solver=\"newton-cg\", max_iter=100, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imputation taken seriously\n",
    "### OS\n",
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: missing data found and removed. Old input shape: 2000, 14, new input shape: 1452, 14\n",
      "train size 1247, test size 205\n"
     ]
    }
   ],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "X = df[traffic_columns]\n",
    "y = df['OS_clean']\n",
    "data = buildTrain(X, y, perc=0.85)\n",
    "print('train size %d, test size %d' % (data.get_size()))\n",
    "build_seed = 456245\n",
    "my_perc = perc(build_seed)\n",
    "my_MLP = MLP(build_seed)\n",
    "my_lr = LogReg(build_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run=1 tscore=0.0221774 vscore=0.0196078\n",
      "run=2 tscore=0.0231855 vscore=0.0196078\n",
      "run=3 tscore=0.0231855 vscore=0.0196078\n",
      "run=4 tscore=0.0262097 vscore=0.0196078\n",
      "run=5 tscore=0.0262097 vscore=0.0196078\n",
      "run=6 tscore=0.0262097 vscore=0.0196078\n",
      "run=7 tscore=0.0272177 vscore=0.0196078\n",
      "run=8 tscore=0.0282258 vscore=0.0235294\n",
      "run=9 tscore=0.0292339 vscore=0.0313725\n",
      "run=10 tscore=0.03125 vscore=0.0431373\n",
      "run=11 tscore=0.0362903 vscore=0.0627451\n",
      "run=12 tscore=0.0433468 vscore=0.0705882\n",
      "run=13 tscore=0.0544355 vscore=0.0823529\n",
      "run=14 tscore=0.0695565 vscore=0.0901961\n",
      "run=15 tscore=0.0907258 vscore=0.105882\n",
      "run=16 tscore=0.146169 vscore=0.12549\n",
      "run=17 tscore=0.266129 vscore=0.243137\n",
      "run=18 tscore=0.397177 vscore=0.368627\n",
      "run=19 tscore=0.471774 vscore=0.447059\n",
      "run=20 tscore=0.534274 vscore=0.509804\n",
      "run=21 tscore=0.570565 vscore=0.545098\n",
      "run=22 tscore=0.579637 vscore=0.54902\n",
      "run=23 tscore=0.582661 vscore=0.54902\n",
      "run=24 tscore=0.58871 vscore=0.54902\n",
      "run=25 tscore=0.589718 vscore=0.54902\n",
      "run=26 tscore=0.59375 vscore=0.54902\n",
      "run=27 tscore=0.596774 vscore=0.552941\n",
      "run=28 tscore=0.599798 vscore=0.552941\n",
      "run=29 tscore=0.599798 vscore=0.552941\n",
      "run=30 tscore=0.601815 vscore=0.552941\n",
      "run=31 tscore=0.601815 vscore=0.552941\n",
      "run=32 tscore=0.602823 vscore=0.552941\n",
      "run=33 tscore=0.603831 vscore=0.552941\n",
      "run=34 tscore=0.604839 vscore=0.552941\n",
      "run=35 tscore=0.604839 vscore=0.552941\n",
      "run=36 tscore=0.604839 vscore=0.552941\n",
      "run=37 tscore=0.605847 vscore=0.552941\n",
      "run=38 tscore=0.605847 vscore=0.552941\n",
      "run=39 tscore=0.606855 vscore=0.552941\n",
      "run=40 tscore=0.606855 vscore=0.552941\n",
      "run=41 tscore=0.605847 vscore=0.552941\n",
      "run=42 tscore=0.605847 vscore=0.552941\n",
      "run=43 tscore=0.605847 vscore=0.552941\n",
      "run=44 tscore=0.605847 vscore=0.552941\n",
      "run=45 tscore=0.605847 vscore=0.552941\n",
      "run=46 tscore=0.605847 vscore=0.552941\n",
      "run=47 tscore=0.605847 vscore=0.552941\n",
      "run=48 tscore=0.605847 vscore=0.552941\n",
      "run=49 tscore=0.605847 vscore=0.552941\n",
      "run=50 tscore=0.604839 vscore=0.552941\n",
      "run=51 tscore=0.604839 vscore=0.552941\n",
      "run=52 tscore=0.603831 vscore=0.552941\n",
      "run=53 tscore=0.603831 vscore=0.552941\n",
      "run=54 tscore=0.603831 vscore=0.552941\n",
      "run=55 tscore=0.603831 vscore=0.552941\n",
      "run=56 tscore=0.603831 vscore=0.552941\n",
      "run=57 tscore=0.603831 vscore=0.552941\n",
      "run=58 tscore=0.603831 vscore=0.552941\n",
      "run=59 tscore=0.603831 vscore=0.552941\n",
      "run=60 tscore=0.603831 vscore=0.552941\n",
      "run=61 tscore=0.603831 vscore=0.552941\n",
      "run=62 tscore=0.603831 vscore=0.552941\n",
      "run=63 tscore=0.603831 vscore=0.552941\n",
      "run=64 tscore=0.603831 vscore=0.552941\n",
      "run=65 tscore=0.603831 vscore=0.552941\n",
      "run=66 tscore=0.603831 vscore=0.552941\n",
      "run=67 tscore=0.603831 vscore=0.552941\n",
      "run=68 tscore=0.603831 vscore=0.552941\n",
      "run=69 tscore=0.603831 vscore=0.552941\n",
      "run=70 tscore=0.603831 vscore=0.552941\n",
      "run=71 tscore=0.603831 vscore=0.552941\n",
      "run=72 tscore=0.603831 vscore=0.552941\n",
      "run=73 tscore=0.603831 vscore=0.552941\n",
      "run=74 tscore=0.603831 vscore=0.552941\n",
      "run=75 tscore=0.603831 vscore=0.552941\n",
      "run=76 tscore=0.603831 vscore=0.552941\n",
      "run=77 tscore=0.603831 vscore=0.552941\n",
      "run=78 tscore=0.603831 vscore=0.552941\n",
      "run=79 tscore=0.603831 vscore=0.552941\n",
      "run=80 tscore=0.603831 vscore=0.552941\n",
      "run=81 tscore=0.603831 vscore=0.552941\n",
      "run=82 tscore=0.603831 vscore=0.552941\n",
      "run=83 tscore=0.603831 vscore=0.552941\n",
      "run=84 tscore=0.603831 vscore=0.556863\n",
      "run=85 tscore=0.603831 vscore=0.556863\n",
      "run=86 tscore=0.603831 vscore=0.556863\n",
      "run=87 tscore=0.603831 vscore=0.556863\n",
      "run=88 tscore=0.603831 vscore=0.556863\n",
      "run=89 tscore=0.603831 vscore=0.556863\n",
      "run=90 tscore=0.603831 vscore=0.556863\n",
      "run=91 tscore=0.603831 vscore=0.556863\n",
      "run=92 tscore=0.603831 vscore=0.556863\n",
      "run=93 tscore=0.603831 vscore=0.556863\n",
      "run=94 tscore=0.603831 vscore=0.556863\n",
      "run=95 tscore=0.603831 vscore=0.556863\n",
      "run=96 tscore=0.603831 vscore=0.556863\n",
      "run=97 tscore=0.603831 vscore=0.556863\n",
      "run=98 tscore=0.603831 vscore=0.556863\n",
      "run=99 tscore=0.603831 vscore=0.556863\n",
      "run=100 tscore=0.603831 vscore=0.556863\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nALFoXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aaf3b52588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_perc.train(*data.get_train(), percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=100,  loss='log', \n",
    "              penalty='none', alpha=1e-8, power_t=0.7, it_interval=100, learning_rate='constant', eta0=1e-8,\n",
    "              class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guglielmo\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 loss=0.8419255081646261 tscore=0.6038306451612904 vscore=0.5568627450980392\n",
      "epoch=1 loss=0.7361353556535457 tscore=0.6129032258064516 vscore=0.5764705882352941\n",
      "epoch=2 loss=0.7208177788593417 tscore=0.6129032258064516 vscore=0.5843137254901961\n",
      "epoch=3 loss=0.7023851069133257 tscore=0.6280241935483871 vscore=0.5882352941176471\n",
      "epoch=4 loss=0.6836055711556146 tscore=0.6592741935483871 vscore=0.6549019607843137\n",
      "epoch=5 loss=0.6764239466185951 tscore=0.6653225806451613 vscore=0.6549019607843137\n",
      "epoch=6 loss=0.6661861132309715 tscore=0.688508064516129 vscore=0.6784313725490196\n",
      "epoch=7 loss=0.6487486954066244 tscore=0.657258064516129 vscore=0.6431372549019608\n",
      "epoch=8 loss=0.6383212007996504 tscore=0.6834677419354839 vscore=0.6509803921568628\n",
      "epoch=9 loss=0.6249402068757307 tscore=0.7792338709677419 vscore=0.7764705882352941\n",
      "epoch=10 loss=0.6173953130053738 tscore=0.8024193548387096 vscore=0.792156862745098\n",
      "epoch=11 loss=0.6049828946118909 tscore=0.7893145161290323 vscore=0.7803921568627451\n",
      "epoch=12 loss=0.6190971179601773 tscore=0.7419354838709677 vscore=0.7372549019607844\n",
      "epoch=13 loss=0.5950077850743649 tscore=0.7923387096774194 vscore=0.788235294117647\n",
      "epoch=14 loss=0.5750915393717809 tscore=0.8064516129032258 vscore=0.788235294117647\n",
      "epoch=15 loss=0.5683626283111983 tscore=0.8215725806451613 vscore=0.807843137254902\n",
      "epoch=16 loss=0.5577157200159338 tscore=0.8165322580645161 vscore=0.807843137254902\n",
      "epoch=17 loss=0.5656112182464093 tscore=0.8256048387096774 vscore=0.8156862745098039\n",
      "epoch=18 loss=0.5459056361476352 tscore=0.8064516129032258 vscore=0.7725490196078432\n",
      "epoch=19 loss=0.5375392841645099 tscore=0.8165322580645161 vscore=0.7843137254901961\n",
      "epoch=20 loss=0.5227693338130585 tscore=0.7852822580645161 vscore=0.7803921568627451\n",
      "epoch=21 loss=0.518873861760697 tscore=0.7631048387096774 vscore=0.7529411764705882\n",
      "epoch=22 loss=0.5244720346153354 tscore=0.7741935483870968 vscore=0.7803921568627451\n",
      "epoch=23 loss=0.5007017550349927 tscore=0.8034274193548387 vscore=0.796078431372549\n",
      "epoch=24 loss=0.49900147457337113 tscore=0.7832661290322581 vscore=0.7647058823529411\n",
      "epoch=25 loss=0.48972979716832876 tscore=0.7872983870967742 vscore=0.796078431372549\n",
      "epoch=26 loss=0.5006965824156293 tscore=0.7872983870967742 vscore=0.7764705882352941\n",
      "epoch=27 loss=0.4844484283091202 tscore=0.8044354838709677 vscore=0.803921568627451\n",
      "epoch=28 loss=0.48282355697683266 tscore=0.8276209677419355 vscore=0.803921568627451\n",
      "epoch=29 loss=0.4748853367785276 tscore=0.8225806451612904 vscore=0.803921568627451\n",
      "epoch=30 loss=0.4732018856663503 tscore=0.8024193548387096 vscore=0.803921568627451\n",
      "epoch=31 loss=0.4628632579034081 tscore=0.8054435483870968 vscore=0.803921568627451\n",
      "epoch=32 loss=0.45728441509920204 tscore=0.8145161290322581 vscore=0.807843137254902\n",
      "epoch=33 loss=0.45635783318266887 tscore=0.8669354838709677 vscore=0.8509803921568627\n",
      "epoch=34 loss=0.4535834079862498 tscore=0.8508064516129032 vscore=0.8470588235294118\n",
      "epoch=35 loss=0.45999039188119517 tscore=0.842741935483871 vscore=0.8274509803921568\n",
      "epoch=36 loss=0.45435329673807706 tscore=0.8145161290322581 vscore=0.803921568627451\n",
      "epoch=37 loss=0.4544249497996435 tscore=0.8165322580645161 vscore=0.796078431372549\n",
      "epoch=38 loss=0.4459754267659664 tscore=0.844758064516129 vscore=0.8352941176470589\n",
      "epoch=39 loss=0.44414068612485447 tscore=0.873991935483871 vscore=0.8549019607843137\n",
      "epoch=40 loss=0.45334613770875565 tscore=0.8719758064516129 vscore=0.8666666666666667\n",
      "epoch=41 loss=0.4401607849090865 tscore=0.8659274193548387 vscore=0.8549019607843137\n",
      "epoch=42 loss=0.4372222039402534 tscore=0.8618951612903226 vscore=0.8588235294117647\n",
      "epoch=43 loss=0.4315511944503356 tscore=0.8538306451612904 vscore=0.8352941176470589\n",
      "epoch=44 loss=0.42658200258021856 tscore=0.8497983870967742 vscore=0.8470588235294118\n",
      "epoch=45 loss=0.42160339339453484 tscore=0.8679435483870968 vscore=0.8627450980392157\n",
      "epoch=46 loss=0.4328067219710383 tscore=0.8387096774193549 vscore=0.8274509803921568\n",
      "epoch=47 loss=0.42443446760060344 tscore=0.8377016129032258 vscore=0.8235294117647058\n",
      "epoch=48 loss=0.41698686497395065 tscore=0.8629032258064516 vscore=0.8627450980392157\n",
      "epoch=49 loss=0.42060697401509517 tscore=0.8770161290322581 vscore=0.8705882352941177\n",
      "epoch=50 loss=0.43255114134928424 tscore=0.873991935483871 vscore=0.8588235294117647\n",
      "epoch=51 loss=0.45152508123653634 tscore=0.8558467741935484 vscore=0.8392156862745098\n",
      "epoch=52 loss=0.427313550086446 tscore=0.8326612903225806 vscore=0.807843137254902\n",
      "epoch=53 loss=0.4203333183949369 tscore=0.8639112903225806 vscore=0.8509803921568627\n",
      "epoch=54 loss=0.4103312174584054 tscore=0.8558467741935484 vscore=0.8666666666666667\n",
      "epoch=55 loss=0.4059612449495638 tscore=0.8649193548387096 vscore=0.8549019607843137\n",
      "epoch=56 loss=0.40503592748592576 tscore=0.8538306451612904 vscore=0.8470588235294118\n",
      "epoch=57 loss=0.40885105183131587 tscore=0.8669354838709677 vscore=0.8627450980392157\n",
      "epoch=58 loss=0.40449116128955975 tscore=0.8558467741935484 vscore=0.8509803921568627\n",
      "epoch=59 loss=0.4049268443793933 tscore=0.8709677419354839 vscore=0.8588235294117647\n",
      "epoch=60 loss=0.4011697557462868 tscore=0.8568548387096774 vscore=0.8549019607843137\n",
      "epoch=61 loss=0.40315491164765654 tscore=0.8689516129032258 vscore=0.8666666666666667\n",
      "epoch=62 loss=0.403175164515058 tscore=0.8719758064516129 vscore=0.8627450980392157\n",
      "epoch=63 loss=0.40071289209148675 tscore=0.8961693548387096 vscore=0.8705882352941177\n",
      "epoch=64 loss=0.40675091326790064 tscore=0.8699596774193549 vscore=0.8666666666666667\n",
      "epoch=65 loss=0.4072340542590014 tscore=0.8467741935483871 vscore=0.8196078431372549\n",
      "epoch=66 loss=0.4093380841819109 tscore=0.8457661290322581 vscore=0.8196078431372549\n",
      "epoch=67 loss=0.41618318911596286 tscore=0.8911290322580645 vscore=0.8745098039215686\n",
      "epoch=68 loss=0.4060582608034057 tscore=0.8971774193548387 vscore=0.8745098039215686\n",
      "epoch=69 loss=0.39796529188327423 tscore=0.8840725806451613 vscore=0.8745098039215686\n",
      "epoch=70 loss=0.39361601276418123 tscore=0.8528225806451613 vscore=0.8352941176470589\n",
      "epoch=71 loss=0.4064086495544393 tscore=0.8891129032258065 vscore=0.8862745098039215\n",
      "epoch=72 loss=0.39565624109145026 tscore=0.8709677419354839 vscore=0.8666666666666667\n",
      "epoch=73 loss=0.3860262224026744 tscore=0.8669354838709677 vscore=0.8431372549019608\n",
      "epoch=74 loss=0.3907210119010994 tscore=0.8699596774193549 vscore=0.8627450980392157\n",
      "epoch=75 loss=0.39210951336695854 tscore=0.8709677419354839 vscore=0.8627450980392157\n",
      "epoch=76 loss=0.38580831233141427 tscore=0.8719758064516129 vscore=0.8627450980392157\n",
      "epoch=77 loss=0.39168632457387587 tscore=0.8669354838709677 vscore=0.8588235294117647\n",
      "epoch=78 loss=0.3867603893355127 tscore=0.876008064516129 vscore=0.8588235294117647\n",
      "epoch=79 loss=0.38482584225862704 tscore=0.8971774193548387 vscore=0.8784313725490196\n",
      "epoch=80 loss=0.3874665171056121 tscore=0.8891129032258065 vscore=0.8784313725490196\n",
      "epoch=81 loss=0.3834541608975022 tscore=0.8850806451612904 vscore=0.8745098039215686\n",
      "epoch=82 loss=0.3837541742828437 tscore=0.8981854838709677 vscore=0.8784313725490196\n",
      "epoch=83 loss=0.3820375682820239 tscore=0.8850806451612904 vscore=0.8627450980392157\n",
      "epoch=84 loss=0.38780366119570325 tscore=0.8951612903225806 vscore=0.8784313725490196\n",
      "epoch=85 loss=0.39150830596811226 tscore=0.8598790322580645 vscore=0.8274509803921568\n",
      "epoch=86 loss=0.3995979809806375 tscore=0.8991935483870968 vscore=0.8823529411764706\n",
      "epoch=87 loss=0.399690915194408 tscore=0.8548387096774194 vscore=0.8392156862745098\n",
      "epoch=88 loss=0.43479150567988417 tscore=0.8649193548387096 vscore=0.8705882352941177\n",
      "epoch=89 loss=0.39512310970334125 tscore=0.8689516129032258 vscore=0.8549019607843137\n",
      "epoch=90 loss=0.38221268446363205 tscore=0.8891129032258065 vscore=0.8745098039215686\n",
      "epoch=91 loss=0.3818152669204283 tscore=0.8921370967741935 vscore=0.8745098039215686\n",
      "epoch=92 loss=0.3989656683019149 tscore=0.8548387096774194 vscore=0.8196078431372549\n",
      "epoch=93 loss=0.4103807241637714 tscore=0.8840725806451613 vscore=0.8666666666666667\n",
      "epoch=94 loss=0.40319618950903485 tscore=0.8971774193548387 vscore=0.8784313725490196\n",
      "epoch=95 loss=0.38574359435837674 tscore=0.9032258064516129 vscore=0.8784313725490196\n",
      "epoch=96 loss=0.3729569030124823 tscore=0.876008064516129 vscore=0.8666666666666667\n",
      "epoch=97 loss=0.3827363076528775 tscore=0.8991935483870968 vscore=0.8784313725490196\n",
      "epoch=98 loss=0.40674953145049786 tscore=0.8901209677419355 vscore=0.8862745098039215\n",
      "epoch=99 loss=0.4282009307941834 tscore=0.8679435483870968 vscore=0.8705882352941177\n",
      "epoch=100 loss=0.4049753953718135 tscore=0.8649193548387096 vscore=0.8274509803921568\n",
      "epoch=101 loss=0.3891650012715202 tscore=0.8719758064516129 vscore=0.8627450980392157\n",
      "epoch=102 loss=0.37573779790188294 tscore=0.8971774193548387 vscore=0.8784313725490196\n",
      "epoch=103 loss=0.3706864870158419 tscore=0.905241935483871 vscore=0.8823529411764706\n",
      "epoch=104 loss=0.3740178838246833 tscore=0.8961693548387096 vscore=0.8784313725490196\n",
      "epoch=105 loss=0.37588218457063644 tscore=0.8981854838709677 vscore=0.8823529411764706\n",
      "epoch=106 loss=0.3866065834310606 tscore=0.8800403225806451 vscore=0.8627450980392157\n",
      "epoch=107 loss=0.3896947387596638 tscore=0.8820564516129032 vscore=0.8666666666666667\n",
      "epoch=108 loss=0.37934859569820173 tscore=0.9032258064516129 vscore=0.8745098039215686\n",
      "epoch=109 loss=0.375066483828696 tscore=0.8790322580645161 vscore=0.8627450980392157\n",
      "epoch=110 loss=0.36907106469343 tscore=0.8830645161290323 vscore=0.8666666666666667\n",
      "epoch=111 loss=0.3739759241036522 tscore=0.9012096774193549 vscore=0.8823529411764706\n",
      "epoch=112 loss=0.37523598422557375 tscore=0.9022177419354839 vscore=0.8745098039215686\n",
      "epoch=113 loss=0.39835980899878776 tscore=0.8921370967741935 vscore=0.8666666666666667\n",
      "epoch=114 loss=0.3779163415538341 tscore=0.8699596774193549 vscore=0.8666666666666667\n",
      "epoch=115 loss=0.3766195421755324 tscore=0.9112903225806451 vscore=0.8784313725490196\n",
      "epoch=116 loss=0.36783699765015376 tscore=0.9002016129032258 vscore=0.8823529411764706\n",
      "epoch=117 loss=0.3717264821264708 tscore=0.8790322580645161 vscore=0.8666666666666667\n",
      "epoch=118 loss=0.3661549848999934 tscore=0.8951612903225806 vscore=0.8745098039215686\n",
      "epoch=119 loss=0.3655587934543593 tscore=0.8951612903225806 vscore=0.8627450980392157\n",
      "epoch=120 loss=0.367479094563292 tscore=0.9012096774193549 vscore=0.8745098039215686\n",
      "epoch=121 loss=0.3680785182582889 tscore=0.9012096774193549 vscore=0.8784313725490196\n",
      "epoch=122 loss=0.3659997462077373 tscore=0.8921370967741935 vscore=0.8627450980392157\n",
      "epoch=123 loss=0.3673712000429038 tscore=0.8709677419354839 vscore=0.8392156862745098\n",
      "epoch=124 loss=0.3729719988163961 tscore=0.8770161290322581 vscore=0.8627450980392157\n",
      "epoch=125 loss=0.3700751396621495 tscore=0.9042338709677419 vscore=0.8627450980392157\n",
      "epoch=126 loss=0.3679010914281118 tscore=0.8679435483870968 vscore=0.8509803921568627\n",
      "epoch=127 loss=0.375610692243421 tscore=0.9122983870967742 vscore=0.8784313725490196\n",
      "epoch=128 loss=0.38312997189310205 tscore=0.9042338709677419 vscore=0.8745098039215686\n",
      "epoch=129 loss=0.3838567221563181 tscore=0.8639112903225806 vscore=0.8117647058823529\n",
      "epoch=130 loss=0.38163026410436124 tscore=0.873991935483871 vscore=0.8588235294117647\n",
      "epoch=131 loss=0.38789534801648173 tscore=0.9092741935483871 vscore=0.8784313725490196\n",
      "epoch=132 loss=0.36629574692227024 tscore=0.90625 vscore=0.8823529411764706\n",
      "epoch=133 loss=0.36495482916594113 tscore=0.8850806451612904 vscore=0.8627450980392157\n",
      "epoch=134 loss=0.3672713149518578 tscore=0.8870967741935484 vscore=0.8705882352941177\n",
      "epoch=135 loss=0.3602441252823268 tscore=0.9112903225806451 vscore=0.8745098039215686\n",
      "epoch=136 loss=0.36168000183061627 tscore=0.8780241935483871 vscore=0.8666666666666667\n",
      "epoch=137 loss=0.36658491952369965 tscore=0.8941532258064516 vscore=0.8745098039215686\n",
      "epoch=138 loss=0.36003106509297994 tscore=0.905241935483871 vscore=0.8745098039215686\n",
      "epoch=139 loss=0.3594040581923212 tscore=0.9133064516129032 vscore=0.8784313725490196\n",
      "epoch=140 loss=0.3664146611280123 tscore=0.9143145161290323 vscore=0.8705882352941177\n",
      "epoch=141 loss=0.37656384004705346 tscore=0.8780241935483871 vscore=0.8627450980392157\n",
      "epoch=142 loss=0.37199279819278225 tscore=0.8669354838709677 vscore=0.8274509803921568\n",
      "epoch=143 loss=0.3710609028350439 tscore=0.8840725806451613 vscore=0.8627450980392157\n",
      "epoch=144 loss=0.3672990593898377 tscore=0.9042338709677419 vscore=0.8784313725490196\n",
      "epoch=145 loss=0.38038917388673293 tscore=0.9173387096774194 vscore=0.8627450980392157\n",
      "epoch=146 loss=0.3620482660953055 tscore=0.8931451612903226 vscore=0.8666666666666667\n",
      "epoch=147 loss=0.37142072920602187 tscore=0.8931451612903226 vscore=0.8627450980392157\n",
      "epoch=148 loss=0.3596278485420235 tscore=0.9042338709677419 vscore=0.8705882352941177\n",
      "epoch=149 loss=0.3697151459112431 tscore=0.8951612903225806 vscore=0.8666666666666667\n",
      "epoch=150 loss=0.36012488801297804 tscore=0.90625 vscore=0.8745098039215686\n",
      "epoch=151 loss=0.3583282911703442 tscore=0.90625 vscore=0.8745098039215686\n",
      "epoch=152 loss=0.35885568863596556 tscore=0.8780241935483871 vscore=0.8470588235294118\n",
      "epoch=153 loss=0.3663263584417605 tscore=0.9133064516129032 vscore=0.8784313725490196\n",
      "epoch=154 loss=0.3568176885130555 tscore=0.9173387096774194 vscore=0.8745098039215686\n",
      "epoch=155 loss=0.3581591992526022 tscore=0.9143145161290323 vscore=0.8705882352941177\n",
      "epoch=156 loss=0.36201012006327515 tscore=0.9012096774193549 vscore=0.8705882352941177\n",
      "epoch=157 loss=0.3569875161759407 tscore=0.9163306451612904 vscore=0.8666666666666667\n",
      "epoch=158 loss=0.36183740028713146 tscore=0.9122983870967742 vscore=0.8784313725490196\n",
      "epoch=159 loss=0.3572886973727141 tscore=0.8891129032258065 vscore=0.8705882352941177\n",
      "epoch=160 loss=0.35740834391502935 tscore=0.8961693548387096 vscore=0.8745098039215686\n",
      "epoch=161 loss=0.35954596545228873 tscore=0.9002016129032258 vscore=0.8666666666666667\n",
      "epoch=162 loss=0.3611564341399024 tscore=0.9092741935483871 vscore=0.8784313725490196\n",
      "epoch=163 loss=0.3680662859198568 tscore=0.8850806451612904 vscore=0.8666666666666667\n",
      "epoch=164 loss=0.36706409987566896 tscore=0.8780241935483871 vscore=0.8509803921568627\n",
      "epoch=165 loss=0.36148220619171556 tscore=0.9002016129032258 vscore=0.8666666666666667\n",
      "epoch=166 loss=0.35764194772011826 tscore=0.9022177419354839 vscore=0.8705882352941177\n",
      "epoch=167 loss=0.3781395960580428 tscore=0.9183467741935484 vscore=0.8588235294117647\n",
      "epoch=168 loss=0.3674613785557099 tscore=0.8850806451612904 vscore=0.8705882352941177\n",
      "epoch=169 loss=0.3545609556695854 tscore=0.9122983870967742 vscore=0.8745098039215686\n",
      "epoch=170 loss=0.36891270121536146 tscore=0.9163306451612904 vscore=0.8823529411764706\n",
      "epoch=171 loss=0.36823949369905545 tscore=0.8810483870967742 vscore=0.8627450980392157\n",
      "epoch=172 loss=0.3603847555261712 tscore=0.9203629032258065 vscore=0.8705882352941177\n",
      "epoch=173 loss=0.3770504923895758 tscore=0.9143145161290323 vscore=0.8823529411764706\n",
      "epoch=174 loss=0.3698102714125382 tscore=0.9092741935483871 vscore=0.8705882352941177\n",
      "epoch=175 loss=0.36126968569449824 tscore=0.8840725806451613 vscore=0.8549019607843137\n",
      "epoch=176 loss=0.35556919863659714 tscore=0.8961693548387096 vscore=0.8745098039215686\n",
      "epoch=177 loss=0.3508682204697557 tscore=0.8820564516129032 vscore=0.8588235294117647\n",
      "epoch=178 loss=0.3563743009915972 tscore=0.8961693548387096 vscore=0.8784313725490196\n",
      "epoch=179 loss=0.3517293738412671 tscore=0.8810483870967742 vscore=0.8549019607843137\n",
      "epoch=180 loss=0.3549827867442445 tscore=0.8991935483870968 vscore=0.8705882352941177\n",
      "epoch=181 loss=0.35504529483609454 tscore=0.8881048387096774 vscore=0.8549019607843137\n",
      "epoch=182 loss=0.3541913449619362 tscore=0.8991935483870968 vscore=0.8784313725490196\n",
      "epoch=183 loss=0.3514550764366671 tscore=0.9163306451612904 vscore=0.8784313725490196\n",
      "epoch=184 loss=0.3532389392514293 tscore=0.8921370967741935 vscore=0.8705882352941177\n",
      "epoch=185 loss=0.3516632678632179 tscore=0.9163306451612904 vscore=0.8745098039215686\n",
      "epoch=186 loss=0.3504675676705366 tscore=0.9203629032258065 vscore=0.8705882352941177\n",
      "epoch=187 loss=0.3556418953680009 tscore=0.9122983870967742 vscore=0.8705882352941177\n",
      "epoch=188 loss=0.35491768080071423 tscore=0.9153225806451613 vscore=0.8745098039215686\n",
      "epoch=189 loss=0.349009995782654 tscore=0.90625 vscore=0.8784313725490196\n",
      "epoch=190 loss=0.35026031049439077 tscore=0.9122983870967742 vscore=0.8627450980392157\n",
      "epoch=191 loss=0.351875845196716 tscore=0.9223790322580645 vscore=0.8784313725490196\n",
      "epoch=192 loss=0.357641147296176 tscore=0.9133064516129032 vscore=0.8784313725490196\n",
      "epoch=193 loss=0.35723458494977195 tscore=0.9002016129032258 vscore=0.8627450980392157\n",
      "epoch=194 loss=0.35305291634486524 tscore=0.9133064516129032 vscore=0.8745098039215686\n",
      "epoch=195 loss=0.3553448897407627 tscore=0.9153225806451613 vscore=0.8666666666666667\n",
      "epoch=196 loss=0.3546975026577398 tscore=0.8891129032258065 vscore=0.8588235294117647\n",
      "epoch=197 loss=0.35280946129993107 tscore=0.9193548387096774 vscore=0.8823529411764706\n",
      "epoch=198 loss=0.35720907265969276 tscore=0.9163306451612904 vscore=0.8823529411764706\n",
      "epoch=199 loss=0.3455946252196293 tscore=0.8991935483870968 vscore=0.8627450980392157\n",
      "epoch=200 loss=0.353807090325571 tscore=0.9193548387096774 vscore=0.8745098039215686\n",
      "epoch=201 loss=0.3522338386213962 tscore=0.9153225806451613 vscore=0.8705882352941177\n",
      "epoch=202 loss=0.34525192897430257 tscore=0.9254032258064516 vscore=0.8784313725490196\n",
      "epoch=203 loss=0.3480924816885016 tscore=0.9163306451612904 vscore=0.8705882352941177\n",
      "epoch=204 loss=0.34801646658048024 tscore=0.9002016129032258 vscore=0.8705882352941177\n",
      "epoch=205 loss=0.3495894136522266 tscore=0.905241935483871 vscore=0.8627450980392157\n",
      "epoch=206 loss=0.3537104650157162 tscore=0.9213709677419355 vscore=0.8784313725490196\n",
      "epoch=207 loss=0.3607373259520865 tscore=0.9233870967741935 vscore=0.8745098039215686\n",
      "epoch=208 loss=0.35542590597739426 tscore=0.8931451612903226 vscore=0.8705882352941177\n",
      "epoch=209 loss=0.3558981572236931 tscore=0.8850806451612904 vscore=0.8588235294117647\n",
      "epoch=210 loss=0.3527910628870725 tscore=0.9153225806451613 vscore=0.8705882352941177\n",
      "epoch=211 loss=0.35492283280616205 tscore=0.9203629032258065 vscore=0.8745098039215686\n",
      "epoch=212 loss=0.3621086110435111 tscore=0.9092741935483871 vscore=0.8666666666666667\n",
      "epoch=213 loss=0.3513595461951274 tscore=0.9223790322580645 vscore=0.8705882352941177\n",
      "epoch=214 loss=0.3508859341427783 tscore=0.9274193548387096 vscore=0.8745098039215686\n",
      "epoch=215 loss=0.36122534666126926 tscore=0.8790322580645161 vscore=0.8627450980392157\n",
      "epoch=216 loss=0.3792404639858053 tscore=0.8921370967741935 vscore=0.8588235294117647\n",
      "epoch=217 loss=0.36240225656511643 tscore=0.9133064516129032 vscore=0.8823529411764706\n",
      "epoch=218 loss=0.35182051328893543 tscore=0.9122983870967742 vscore=0.8627450980392157\n",
      "epoch=219 loss=0.3506828489456046 tscore=0.9173387096774194 vscore=0.8745098039215686\n",
      "epoch=220 loss=0.35419310030865586 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=221 loss=0.3443821766145562 tscore=0.9173387096774194 vscore=0.8745098039215686\n",
      "epoch=222 loss=0.34333703931751747 tscore=0.8921370967741935 vscore=0.8745098039215686\n",
      "epoch=223 loss=0.3572730931714747 tscore=0.9203629032258065 vscore=0.8705882352941177\n",
      "epoch=224 loss=0.3651632186581771 tscore=0.9193548387096774 vscore=0.8823529411764706\n",
      "epoch=225 loss=0.35274816621148974 tscore=0.9022177419354839 vscore=0.8705882352941177\n",
      "epoch=226 loss=0.34643958711464223 tscore=0.8840725806451613 vscore=0.8588235294117647\n",
      "epoch=227 loss=0.36373737075312784 tscore=0.9193548387096774 vscore=0.8627450980392157\n",
      "epoch=228 loss=0.3748366904006523 tscore=0.9193548387096774 vscore=0.8784313725490196\n",
      "epoch=229 loss=0.35409250622117455 tscore=0.9193548387096774 vscore=0.8784313725490196\n",
      "epoch=230 loss=0.3473275675190892 tscore=0.9223790322580645 vscore=0.8784313725490196\n",
      "epoch=231 loss=0.34518082583872 tscore=0.9133064516129032 vscore=0.8627450980392157\n",
      "epoch=232 loss=0.3442444567292576 tscore=0.9163306451612904 vscore=0.8705882352941177\n",
      "epoch=233 loss=0.34509809668482533 tscore=0.9254032258064516 vscore=0.8588235294117647\n",
      "epoch=234 loss=0.3442184811814309 tscore=0.9163306451612904 vscore=0.8745098039215686\n",
      "epoch=235 loss=0.3564421148504284 tscore=0.8891129032258065 vscore=0.8549019607843137\n",
      "epoch=236 loss=0.35550129688632276 tscore=0.8800403225806451 vscore=0.8431372549019608\n",
      "epoch=237 loss=0.3571414268626153 tscore=0.9153225806451613 vscore=0.8745098039215686\n",
      "epoch=238 loss=0.35592083320521095 tscore=0.9133064516129032 vscore=0.8666666666666667\n",
      "epoch=239 loss=0.347004700813403 tscore=0.907258064516129 vscore=0.8627450980392157\n",
      "epoch=240 loss=0.36034514632380155 tscore=0.9233870967741935 vscore=0.8784313725490196\n",
      "epoch=241 loss=0.3463282180676721 tscore=0.905241935483871 vscore=0.8666666666666667\n",
      "epoch=242 loss=0.34186323008402525 tscore=0.9032258064516129 vscore=0.8745098039215686\n",
      "epoch=243 loss=0.34978180467369213 tscore=0.9092741935483871 vscore=0.8666666666666667\n",
      "epoch=244 loss=0.34793309899574787 tscore=0.9213709677419355 vscore=0.8745098039215686\n",
      "epoch=245 loss=0.3511573909786814 tscore=0.9254032258064516 vscore=0.8784313725490196\n",
      "epoch=246 loss=0.3483333844798093 tscore=0.8810483870967742 vscore=0.8588235294117647\n",
      "epoch=247 loss=0.3683965478509787 tscore=0.8881048387096774 vscore=0.8588235294117647\n",
      "epoch=248 loss=0.35960571083806797 tscore=0.8941532258064516 vscore=0.8705882352941177\n",
      "epoch=249 loss=0.3483525573081154 tscore=0.9233870967741935 vscore=0.8666666666666667\n",
      "epoch=250 loss=0.34537933386803493 tscore=0.9213709677419355 vscore=0.8862745098039215\n",
      "epoch=251 loss=0.34357533505723553 tscore=0.8850806451612904 vscore=0.8627450980392157\n",
      "epoch=252 loss=0.35741811802438717 tscore=0.9082661290322581 vscore=0.8745098039215686\n",
      "epoch=253 loss=0.3512783013254744 tscore=0.9203629032258065 vscore=0.8784313725490196\n",
      "epoch=254 loss=0.34409465671843614 tscore=0.9254032258064516 vscore=0.8705882352941177\n",
      "epoch=255 loss=0.34492497692782004 tscore=0.9163306451612904 vscore=0.8666666666666667\n",
      "epoch=256 loss=0.36702590162489807 tscore=0.8931451612903226 vscore=0.8509803921568627\n",
      "epoch=257 loss=0.35279722733977864 tscore=0.9254032258064516 vscore=0.8823529411764706\n",
      "epoch=258 loss=0.3499971656115868 tscore=0.9223790322580645 vscore=0.8745098039215686\n",
      "epoch=259 loss=0.35043450611506843 tscore=0.9143145161290323 vscore=0.8666666666666667\n",
      "epoch=260 loss=0.34619130819021676 tscore=0.9203629032258065 vscore=0.8823529411764706\n",
      "epoch=261 loss=0.34643382860990296 tscore=0.9102822580645161 vscore=0.8588235294117647\n",
      "epoch=262 loss=0.3538618993891032 tscore=0.8981854838709677 vscore=0.8627450980392157\n",
      "epoch=263 loss=0.34893185166658486 tscore=0.9183467741935484 vscore=0.8745098039215686\n",
      "epoch=264 loss=0.34304639244780055 tscore=0.9223790322580645 vscore=0.8666666666666667\n",
      "epoch=265 loss=0.3446674192225297 tscore=0.8911290322580645 vscore=0.8588235294117647\n",
      "epoch=266 loss=0.3447361789116791 tscore=0.905241935483871 vscore=0.8627450980392157\n",
      "epoch=267 loss=0.35109933394177634 tscore=0.9193548387096774 vscore=0.8823529411764706\n",
      "epoch=268 loss=0.35294069093228175 tscore=0.9243951612903226 vscore=0.8627450980392157\n",
      "epoch=269 loss=0.34390500870283514 tscore=0.907258064516129 vscore=0.8666666666666667\n",
      "epoch=270 loss=0.3433496201414696 tscore=0.9183467741935484 vscore=0.8627450980392157\n",
      "epoch=271 loss=0.3453178074083572 tscore=0.9193548387096774 vscore=0.8784313725490196\n",
      "epoch=272 loss=0.3515858284214447 tscore=0.8951612903225806 vscore=0.8666666666666667\n",
      "epoch=273 loss=0.35632095645429884 tscore=0.9193548387096774 vscore=0.8745098039215686\n",
      "epoch=274 loss=0.34919716311931986 tscore=0.9233870967741935 vscore=0.8705882352941177\n",
      "epoch=275 loss=0.3492567870214907 tscore=0.8921370967741935 vscore=0.8627450980392157\n",
      "epoch=276 loss=0.35323085348556016 tscore=0.90625 vscore=0.8666666666666667\n",
      "epoch=277 loss=0.3412740651997194 tscore=0.9193548387096774 vscore=0.8666666666666667\n",
      "epoch=278 loss=0.33977677364907255 tscore=0.9264112903225806 vscore=0.8666666666666667\n",
      "epoch=279 loss=0.3389975021783521 tscore=0.9274193548387096 vscore=0.8745098039215686\n",
      "epoch=280 loss=0.34697074854089144 tscore=0.9042338709677419 vscore=0.8705882352941177\n",
      "epoch=281 loss=0.3482734242850812 tscore=0.9264112903225806 vscore=0.8549019607843137\n",
      "epoch=282 loss=0.3487225826574846 tscore=0.9233870967741935 vscore=0.8666666666666667\n",
      "epoch=283 loss=0.34128214768595383 tscore=0.9183467741935484 vscore=0.8666666666666667\n",
      "epoch=284 loss=0.34885418786332106 tscore=0.9032258064516129 vscore=0.8627450980392157\n",
      "epoch=285 loss=0.34808910500887563 tscore=0.9163306451612904 vscore=0.8745098039215686\n",
      "epoch=286 loss=0.3611943959184844 tscore=0.8981854838709677 vscore=0.8666666666666667\n",
      "epoch=287 loss=0.34687411699529214 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=288 loss=0.3384628130586351 tscore=0.907258064516129 vscore=0.8666666666666667\n",
      "epoch=289 loss=0.3447942460735319 tscore=0.90625 vscore=0.8705882352941177\n",
      "epoch=290 loss=0.34562173836947946 tscore=0.90625 vscore=0.8705882352941177\n",
      "epoch=291 loss=0.34150680442239445 tscore=0.9213709677419355 vscore=0.8666666666666667\n",
      "epoch=292 loss=0.3483613189849601 tscore=0.9223790322580645 vscore=0.8745098039215686\n",
      "epoch=293 loss=0.33951770989090607 tscore=0.9243951612903226 vscore=0.8666666666666667\n",
      "epoch=294 loss=0.34091588768356224 tscore=0.9274193548387096 vscore=0.8745098039215686\n",
      "epoch=295 loss=0.3490783223249141 tscore=0.8891129032258065 vscore=0.8627450980392157\n",
      "epoch=296 loss=0.34192384539720033 tscore=0.90625 vscore=0.8666666666666667\n",
      "epoch=297 loss=0.34081482814784975 tscore=0.9042338709677419 vscore=0.8627450980392157\n",
      "epoch=298 loss=0.3383338708838671 tscore=0.9254032258064516 vscore=0.8666666666666667\n",
      "epoch=299 loss=0.346012458198706 tscore=0.9254032258064516 vscore=0.8705882352941177\n",
      "epoch=300 loss=0.3365079842937878 tscore=0.9193548387096774 vscore=0.8666666666666667\n",
      "epoch=301 loss=0.33823233640671524 tscore=0.9102822580645161 vscore=0.8705882352941177\n",
      "epoch=302 loss=0.34195457056738066 tscore=0.9042338709677419 vscore=0.8627450980392157\n",
      "epoch=303 loss=0.3437982389011386 tscore=0.9254032258064516 vscore=0.8784313725490196\n",
      "epoch=304 loss=0.3451476789635882 tscore=0.907258064516129 vscore=0.8666666666666667\n",
      "epoch=305 loss=0.34227740514088595 tscore=0.9284274193548387 vscore=0.8627450980392157\n",
      "epoch=306 loss=0.34638738993863993 tscore=0.9183467741935484 vscore=0.8666666666666667\n",
      "epoch=307 loss=0.34129213715307893 tscore=0.9203629032258065 vscore=0.8823529411764706\n",
      "epoch=308 loss=0.3424653388136167 tscore=0.9243951612903226 vscore=0.8705882352941177\n",
      "epoch=309 loss=0.3397090440245549 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=310 loss=0.3402321418547605 tscore=0.9254032258064516 vscore=0.8705882352941177\n",
      "epoch=311 loss=0.33776506185409805 tscore=0.90625 vscore=0.8588235294117647\n",
      "epoch=312 loss=0.339881787564499 tscore=0.8991935483870968 vscore=0.8627450980392157\n",
      "epoch=313 loss=0.34204315648265116 tscore=0.9264112903225806 vscore=0.8745098039215686\n",
      "epoch=314 loss=0.33938919646514143 tscore=0.9102822580645161 vscore=0.8666666666666667\n",
      "epoch=315 loss=0.33844011627375165 tscore=0.9183467741935484 vscore=0.8627450980392157\n",
      "epoch=316 loss=0.33622214785032006 tscore=0.9223790322580645 vscore=0.8666666666666667\n",
      "epoch=317 loss=0.33957025395480067 tscore=0.9163306451612904 vscore=0.8666666666666667\n",
      "epoch=318 loss=0.3414636182094329 tscore=0.9223790322580645 vscore=0.8666666666666667\n",
      "epoch=319 loss=0.35068915321207306 tscore=0.9122983870967742 vscore=0.8705882352941177\n",
      "epoch=320 loss=0.34503152998861003 tscore=0.9284274193548387 vscore=0.8823529411764706\n",
      "epoch=321 loss=0.3484651408458624 tscore=0.9213709677419355 vscore=0.8705882352941177\n",
      "epoch=322 loss=0.3415514834099959 tscore=0.9133064516129032 vscore=0.8666666666666667\n",
      "epoch=323 loss=0.3573516914266942 tscore=0.9153225806451613 vscore=0.8705882352941177\n",
      "epoch=324 loss=0.3541523478974983 tscore=0.9264112903225806 vscore=0.8666666666666667\n",
      "epoch=325 loss=0.3544528576418348 tscore=0.8790322580645161 vscore=0.8274509803921568\n",
      "epoch=326 loss=0.3978826822636071 tscore=0.8699596774193549 vscore=0.8352941176470589\n",
      "epoch=327 loss=0.37845905145996794 tscore=0.9163306451612904 vscore=0.8705882352941177\n",
      "epoch=328 loss=0.35442140732899824 tscore=0.9233870967741935 vscore=0.8588235294117647\n",
      "epoch=329 loss=0.35371296241773265 tscore=0.9002016129032258 vscore=0.8627450980392157\n",
      "epoch=330 loss=0.3545545182355826 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=331 loss=0.35087037316689046 tscore=0.9153225806451613 vscore=0.8666666666666667\n",
      "epoch=332 loss=0.33306387391545655 tscore=0.9254032258064516 vscore=0.8745098039215686\n",
      "epoch=333 loss=0.34937130232760294 tscore=0.9233870967741935 vscore=0.8627450980392157\n",
      "epoch=334 loss=0.3331421012766108 tscore=0.9223790322580645 vscore=0.8666666666666667\n",
      "epoch=335 loss=0.33439890648317944 tscore=0.9213709677419355 vscore=0.8627450980392157\n",
      "epoch=336 loss=0.3350745540700519 tscore=0.9233870967741935 vscore=0.8705882352941177\n",
      "epoch=337 loss=0.3362445499229789 tscore=0.9133064516129032 vscore=0.8705882352941177\n",
      "epoch=338 loss=0.3388814875245958 tscore=0.9274193548387096 vscore=0.8823529411764706\n",
      "epoch=339 loss=0.34195136908120305 tscore=0.8780241935483871 vscore=0.8352941176470589\n",
      "epoch=340 loss=0.37094680799970176 tscore=0.8921370967741935 vscore=0.8588235294117647\n",
      "epoch=341 loss=0.35702476593457527 tscore=0.9274193548387096 vscore=0.8705882352941177\n",
      "epoch=342 loss=0.3443667108423923 tscore=0.9284274193548387 vscore=0.8784313725490196\n",
      "epoch=343 loss=0.33890149359946165 tscore=0.9032258064516129 vscore=0.8666666666666667\n",
      "epoch=344 loss=0.34098504295054227 tscore=0.9092741935483871 vscore=0.8705882352941177\n",
      "epoch=345 loss=0.3359542276750785 tscore=0.9243951612903226 vscore=0.8705882352941177\n",
      "epoch=346 loss=0.33293947822593967 tscore=0.9143145161290323 vscore=0.8705882352941177\n",
      "epoch=347 loss=0.3467703796349379 tscore=0.9143145161290323 vscore=0.8627450980392157\n",
      "epoch=348 loss=0.35663636125866127 tscore=0.9274193548387096 vscore=0.8823529411764706\n",
      "epoch=349 loss=0.36304750816825676 tscore=0.907258064516129 vscore=0.8588235294117647\n",
      "epoch=350 loss=0.3483033733066365 tscore=0.9264112903225806 vscore=0.8784313725490196\n",
      "epoch=351 loss=0.3395956257741296 tscore=0.9163306451612904 vscore=0.8705882352941177\n",
      "epoch=352 loss=0.3414961213956614 tscore=0.8971774193548387 vscore=0.8588235294117647\n",
      "epoch=353 loss=0.34985617733515856 tscore=0.9183467741935484 vscore=0.8784313725490196\n",
      "epoch=354 loss=0.35252152659565067 tscore=0.9173387096774194 vscore=0.8627450980392157\n",
      "epoch=355 loss=0.34413292733753287 tscore=0.8891129032258065 vscore=0.8470588235294118\n",
      "epoch=356 loss=0.3661983579420384 tscore=0.9213709677419355 vscore=0.8627450980392157\n",
      "epoch=357 loss=0.3395990115137262 tscore=0.9254032258064516 vscore=0.8823529411764706\n",
      "epoch=358 loss=0.33720104184282235 tscore=0.9122983870967742 vscore=0.8745098039215686\n",
      "epoch=359 loss=0.3414132662887028 tscore=0.9213709677419355 vscore=0.8745098039215686\n",
      "epoch=360 loss=0.36041914992775104 tscore=0.9082661290322581 vscore=0.8666666666666667\n",
      "epoch=361 loss=0.35594897892999566 tscore=0.8860887096774194 vscore=0.8392156862745098\n",
      "epoch=362 loss=0.35810204395688144 tscore=0.9304435483870968 vscore=0.8745098039215686\n",
      "epoch=363 loss=0.35142616859025744 tscore=0.9022177419354839 vscore=0.8588235294117647\n",
      "epoch=364 loss=0.36944930922377245 tscore=0.9274193548387096 vscore=0.8666666666666667\n",
      "epoch=365 loss=0.33900214616885876 tscore=0.9173387096774194 vscore=0.8705882352941177\n",
      "epoch=366 loss=0.33783561283852126 tscore=0.9243951612903226 vscore=0.8627450980392157\n",
      "epoch=367 loss=0.3369738181268395 tscore=0.9213709677419355 vscore=0.8705882352941177\n",
      "epoch=368 loss=0.3346710848904986 tscore=0.9284274193548387 vscore=0.8784313725490196\n",
      "epoch=369 loss=0.34769921934568654 tscore=0.9274193548387096 vscore=0.8823529411764706\n",
      "epoch=370 loss=0.3589670527032823 tscore=0.9122983870967742 vscore=0.8705882352941177\n",
      "epoch=371 loss=0.3497340244849278 tscore=0.8991935483870968 vscore=0.8588235294117647\n",
      "epoch=372 loss=0.3498325296155626 tscore=0.9082661290322581 vscore=0.8627450980392157\n",
      "epoch=373 loss=0.34913159135814886 tscore=0.9294354838709677 vscore=0.8666666666666667\n",
      "epoch=374 loss=0.33244177874502134 tscore=0.9254032258064516 vscore=0.8784313725490196\n",
      "epoch=375 loss=0.33588102966262295 tscore=0.9243951612903226 vscore=0.8666666666666667\n",
      "epoch=376 loss=0.33963316971254776 tscore=0.9173387096774194 vscore=0.8666666666666667\n",
      "epoch=377 loss=0.34667516606739407 tscore=0.9254032258064516 vscore=0.8823529411764706\n",
      "epoch=378 loss=0.3373054358943791 tscore=0.9112903225806451 vscore=0.8666666666666667\n",
      "epoch=379 loss=0.3381038977093128 tscore=0.9163306451612904 vscore=0.8705882352941177\n",
      "epoch=380 loss=0.3340056005481298 tscore=0.9294354838709677 vscore=0.8666666666666667\n",
      "epoch=381 loss=0.33427432804828333 tscore=0.9183467741935484 vscore=0.8705882352941177\n",
      "epoch=382 loss=0.32989276951811675 tscore=0.9274193548387096 vscore=0.8627450980392157\n",
      "epoch=383 loss=0.33243022186444093 tscore=0.9233870967741935 vscore=0.8666666666666667\n",
      "epoch=384 loss=0.33291642564867635 tscore=0.9122983870967742 vscore=0.8666666666666667\n",
      "epoch=385 loss=0.3429522753177028 tscore=0.9294354838709677 vscore=0.8745098039215686\n",
      "epoch=386 loss=0.3419641542045022 tscore=0.9284274193548387 vscore=0.8705882352941177\n",
      "epoch=387 loss=0.3345846186531622 tscore=0.9173387096774194 vscore=0.8745098039215686\n",
      "epoch=388 loss=0.3413410159050006 tscore=0.9102822580645161 vscore=0.8588235294117647\n",
      "epoch=389 loss=0.34741653027803115 tscore=0.9243951612903226 vscore=0.8784313725490196\n",
      "epoch=390 loss=0.3508897101413774 tscore=0.9193548387096774 vscore=0.8745098039215686\n",
      "epoch=391 loss=0.3434582494685246 tscore=0.9012096774193549 vscore=0.8705882352941177\n",
      "epoch=392 loss=0.35187245228756614 tscore=0.9112903225806451 vscore=0.8588235294117647\n",
      "epoch=393 loss=0.3388965765639797 tscore=0.9294354838709677 vscore=0.8705882352941177\n",
      "epoch=394 loss=0.3333176958303274 tscore=0.9223790322580645 vscore=0.8666666666666667\n",
      "epoch=395 loss=0.3332524660246794 tscore=0.9213709677419355 vscore=0.8627450980392157\n",
      "epoch=396 loss=0.3396408443430193 tscore=0.9122983870967742 vscore=0.8666666666666667\n",
      "epoch=397 loss=0.34559634844540904 tscore=0.9254032258064516 vscore=0.8745098039215686\n",
      "epoch=398 loss=0.3371461522386315 tscore=0.9274193548387096 vscore=0.8666666666666667\n",
      "epoch=399 loss=0.331578246762815 tscore=0.9233870967741935 vscore=0.8627450980392157\n",
      "epoch=400 loss=0.33957683019001234 tscore=0.9143145161290323 vscore=0.8666666666666667\n",
      "epoch=401 loss=0.33373908316031137 tscore=0.9213709677419355 vscore=0.8666666666666667\n",
      "epoch=402 loss=0.3392250189676977 tscore=0.8881048387096774 vscore=0.8549019607843137\n",
      "epoch=403 loss=0.3672028885006794 tscore=0.9122983870967742 vscore=0.8666666666666667\n",
      "epoch=404 loss=0.34790878156187793 tscore=0.9213709677419355 vscore=0.8823529411764706\n",
      "epoch=405 loss=0.3360905101590592 tscore=0.9294354838709677 vscore=0.8745098039215686\n",
      "epoch=406 loss=0.33879302191483407 tscore=0.9153225806451613 vscore=0.8627450980392157\n",
      "epoch=407 loss=0.33579052075083526 tscore=0.905241935483871 vscore=0.8588235294117647\n",
      "epoch=408 loss=0.3535647557355535 tscore=0.9284274193548387 vscore=0.8627450980392157\n",
      "epoch=409 loss=0.3345477087686567 tscore=0.9264112903225806 vscore=0.8705882352941177\n",
      "epoch=410 loss=0.3409254669653212 tscore=0.9304435483870968 vscore=0.8784313725490196\n",
      "epoch=411 loss=0.3386792758583268 tscore=0.9264112903225806 vscore=0.8666666666666667\n",
      "epoch=412 loss=0.3335291978030157 tscore=0.9183467741935484 vscore=0.8705882352941177\n",
      "epoch=413 loss=0.3351011193864872 tscore=0.9133064516129032 vscore=0.8745098039215686\n",
      "epoch=414 loss=0.33745356599799003 tscore=0.9324596774193549 vscore=0.8745098039215686\n",
      "epoch=415 loss=0.33660697584135546 tscore=0.9284274193548387 vscore=0.8784313725490196\n",
      "epoch=416 loss=0.3421732500855158 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=417 loss=0.3407847283896405 tscore=0.9203629032258065 vscore=0.8745098039215686\n",
      "epoch=418 loss=0.33607711588256606 tscore=0.9112903225806451 vscore=0.8627450980392157\n",
      "epoch=419 loss=0.3333886637589943 tscore=0.9243951612903226 vscore=0.8705882352941177\n",
      "epoch=420 loss=0.33207723699955377 tscore=0.9324596774193549 vscore=0.8784313725490196\n",
      "epoch=421 loss=0.35401289880058934 tscore=0.9042338709677419 vscore=0.8588235294117647\n",
      "epoch=422 loss=0.35904277952026376 tscore=0.9112903225806451 vscore=0.8705882352941177\n",
      "epoch=423 loss=0.36137941551149766 tscore=0.9264112903225806 vscore=0.8705882352941177\n",
      "epoch=424 loss=0.3446874194389197 tscore=0.9274193548387096 vscore=0.8784313725490196\n",
      "epoch=425 loss=0.3431889367318986 tscore=0.9153225806451613 vscore=0.8745098039215686\n",
      "epoch=426 loss=0.33475977046475996 tscore=0.9163306451612904 vscore=0.8627450980392157\n",
      "epoch=427 loss=0.3372885611291145 tscore=0.8961693548387096 vscore=0.8666666666666667\n",
      "epoch=428 loss=0.34162523129875094 tscore=0.9183467741935484 vscore=0.8666666666666667\n",
      "epoch=429 loss=0.33428613577695926 tscore=0.9243951612903226 vscore=0.8627450980392157\n",
      "epoch=430 loss=0.33810489842823116 tscore=0.90625 vscore=0.8627450980392157\n",
      "epoch=431 loss=0.34943889377478327 tscore=0.9082661290322581 vscore=0.8627450980392157\n",
      "epoch=432 loss=0.3490339233446799 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=433 loss=0.349695448609951 tscore=0.9294354838709677 vscore=0.8705882352941177\n",
      "epoch=434 loss=0.33772045245798665 tscore=0.9233870967741935 vscore=0.8823529411764706\n",
      "epoch=435 loss=0.33423597295495283 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=436 loss=0.33141565507963666 tscore=0.9274193548387096 vscore=0.8666666666666667\n",
      "epoch=437 loss=0.33031200064076344 tscore=0.9233870967741935 vscore=0.8705882352941177\n",
      "epoch=438 loss=0.3328891215750364 tscore=0.9314516129032258 vscore=0.8705882352941177\n",
      "epoch=439 loss=0.33854797481849425 tscore=0.9153225806451613 vscore=0.8705882352941177\n",
      "epoch=440 loss=0.3316050753156959 tscore=0.9233870967741935 vscore=0.8627450980392157\n",
      "epoch=441 loss=0.338016431542693 tscore=0.9314516129032258 vscore=0.8745098039215686\n",
      "epoch=442 loss=0.3304763409403321 tscore=0.9213709677419355 vscore=0.8705882352941177\n",
      "epoch=443 loss=0.34491696840856817 tscore=0.9344758064516129 vscore=0.8745098039215686\n",
      "epoch=444 loss=0.35157148449270215 tscore=0.8860887096774194 vscore=0.8431372549019608\n",
      "epoch=445 loss=0.3560118033689402 tscore=0.9233870967741935 vscore=0.8666666666666667\n",
      "epoch=446 loss=0.37542799518189274 tscore=0.8346774193548387 vscore=0.807843137254902\n",
      "epoch=447 loss=0.3936002367901461 tscore=0.9233870967741935 vscore=0.8705882352941177\n",
      "epoch=448 loss=0.3543121639423478 tscore=0.9223790322580645 vscore=0.8745098039215686\n",
      "epoch=449 loss=0.3633086476527282 tscore=0.9274193548387096 vscore=0.8627450980392157\n",
      "epoch=450 loss=0.3512080149663549 tscore=0.9223790322580645 vscore=0.8705882352941177\n",
      "epoch=451 loss=0.33848446959809664 tscore=0.9243951612903226 vscore=0.8705882352941177\n",
      "epoch=452 loss=0.3444930746618888 tscore=0.9153225806451613 vscore=0.8705882352941177\n",
      "epoch=453 loss=0.3383897752253356 tscore=0.9274193548387096 vscore=0.8705882352941177\n",
      "epoch=454 loss=0.33281327632489754 tscore=0.9173387096774194 vscore=0.8745098039215686\n",
      "epoch=455 loss=0.3390606724455182 tscore=0.9122983870967742 vscore=0.8627450980392157\n",
      "epoch=456 loss=0.33264929473609206 tscore=0.9264112903225806 vscore=0.8705882352941177\n",
      "epoch=457 loss=0.32784213070287804 tscore=0.9254032258064516 vscore=0.8705882352941177\n",
      "epoch=458 loss=0.3374661549690257 tscore=0.9304435483870968 vscore=0.8666666666666667\n",
      "epoch=459 loss=0.33383013641922266 tscore=0.9233870967741935 vscore=0.8705882352941177\n",
      "epoch=460 loss=0.32933455808569057 tscore=0.9324596774193549 vscore=0.8745098039215686\n",
      "epoch=461 loss=0.3403127196733466 tscore=0.9254032258064516 vscore=0.8666666666666667\n",
      "epoch=462 loss=0.3393730633977486 tscore=0.9143145161290323 vscore=0.8666666666666667\n",
      "epoch=463 loss=0.3344808920258391 tscore=0.9284274193548387 vscore=0.8666666666666667\n",
      "epoch=464 loss=0.32939187250150537 tscore=0.9254032258064516 vscore=0.8705882352941177\n",
      "epoch=465 loss=0.3305126731196515 tscore=0.8971774193548387 vscore=0.8627450980392157\n",
      "epoch=466 loss=0.3423533356987904 tscore=0.9143145161290323 vscore=0.8784313725490196\n",
      "epoch=467 loss=0.3349153708911114 tscore=0.9032258064516129 vscore=0.8392156862745098\n",
      "epoch=468 loss=0.33532019523878104 tscore=0.9133064516129032 vscore=0.8745098039215686\n",
      "epoch=469 loss=0.32909696497488367 tscore=0.9274193548387096 vscore=0.8666666666666667\n",
      "epoch=470 loss=0.3339781292496354 tscore=0.9284274193548387 vscore=0.8745098039215686\n",
      "epoch=471 loss=0.33499426485145284 tscore=0.9284274193548387 vscore=0.8745098039215686\n",
      "epoch=472 loss=0.33841990184637216 tscore=0.9334677419354839 vscore=0.8627450980392157\n",
      "epoch=473 loss=0.34061426982605747 tscore=0.9243951612903226 vscore=0.8705882352941177\n",
      "epoch=474 loss=0.3514140623260697 tscore=0.905241935483871 vscore=0.8549019607843137\n",
      "epoch=475 loss=0.3559121205781064 tscore=0.9082661290322581 vscore=0.8784313725490196\n",
      "epoch=476 loss=0.33249653248020894 tscore=0.9324596774193549 vscore=0.8666666666666667\n",
      "epoch=477 loss=0.336039960355212 tscore=0.9223790322580645 vscore=0.8666666666666667\n",
      "epoch=478 loss=0.34205397270718324 tscore=0.9133064516129032 vscore=0.8823529411764706\n",
      "epoch=479 loss=0.32896945128552485 tscore=0.9274193548387096 vscore=0.8666666666666667\n",
      "epoch=480 loss=0.33719647570723343 tscore=0.9284274193548387 vscore=0.8745098039215686\n",
      "epoch=481 loss=0.3389207465710651 tscore=0.9002016129032258 vscore=0.8509803921568627\n",
      "epoch=482 loss=0.35907942434251716 tscore=0.9163306451612904 vscore=0.8666666666666667\n",
      "epoch=483 loss=0.33564804275086 tscore=0.9223790322580645 vscore=0.8705882352941177\n",
      "epoch=484 loss=0.33371084566432274 tscore=0.9274193548387096 vscore=0.8745098039215686\n",
      "epoch=485 loss=0.33190528805257813 tscore=0.9092741935483871 vscore=0.8705882352941177\n",
      "epoch=486 loss=0.3286371055614892 tscore=0.9264112903225806 vscore=0.8745098039215686\n",
      "epoch=487 loss=0.3351909070387772 tscore=0.9243951612903226 vscore=0.8745098039215686\n",
      "epoch=488 loss=0.3440016011571652 tscore=0.9314516129032258 vscore=0.8745098039215686\n",
      "epoch=489 loss=0.33259928240508085 tscore=0.9284274193548387 vscore=0.8745098039215686\n",
      "epoch=490 loss=0.33396562523572043 tscore=0.9233870967741935 vscore=0.8745098039215686\n",
      "epoch=491 loss=0.33811512825537243 tscore=0.9042338709677419 vscore=0.8705882352941177\n",
      "epoch=492 loss=0.3491501118380909 tscore=0.9102822580645161 vscore=0.8588235294117647\n",
      "epoch=493 loss=0.3391753747007068 tscore=0.9233870967741935 vscore=0.8823529411764706\n",
      "epoch=494 loss=0.3310741611956592 tscore=0.9304435483870968 vscore=0.8705882352941177\n",
      "epoch=495 loss=0.3433324271089622 tscore=0.9294354838709677 vscore=0.8705882352941177\n",
      "epoch=496 loss=0.3435846049807004 tscore=0.9233870967741935 vscore=0.8666666666666667\n",
      "epoch=497 loss=0.3367598376268417 tscore=0.9274193548387096 vscore=0.8705882352941177\n",
      "epoch=498 loss=0.3354817717559653 tscore=0.9203629032258065 vscore=0.8784313725490196\n",
      "epoch=499 loss=0.3298121081717272 tscore=0.9274193548387096 vscore=0.8666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aaf1808e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_MLP.train(*data.get_train(), percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=500,\n",
    "             hidden_layer_sizes = (200,), batch_size = 100, learning_rate_init=1e-2, solver = 'adam', \n",
    "             learning_rate = 'constant', momentum = 0.5, nesterovs_momentum = False,\n",
    "             alpha = 0.01, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guglielmo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guglielmo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guglielmo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guglielmo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 tscore=0.6038306451612904 vscore=0.5568627450980392\n",
      "epoch=1 tscore=0.6038306451612904 vscore=0.5568627450980392\n",
      "epoch=2 tscore=0.6179435483870968 vscore=0.5882352941176471\n",
      "epoch=3 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=4 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=5 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=6 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=7 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=8 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=9 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=10 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=11 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=12 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=13 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=14 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=15 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=16 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=17 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=18 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=19 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=20 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=21 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=22 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=23 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=24 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=25 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=26 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=27 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=28 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=29 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=30 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=31 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=32 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=33 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=34 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=35 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=36 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=37 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=38 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=39 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=40 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=41 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=42 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=43 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=44 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=45 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=46 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=47 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=48 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=49 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=50 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=51 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=52 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=53 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=54 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=55 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=56 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=57 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=58 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=59 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=60 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=61 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=62 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=63 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=64 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=65 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=66 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=67 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=68 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=69 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=70 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=71 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=72 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=73 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=74 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=75 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=76 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=77 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=78 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=79 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=80 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=81 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=82 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=83 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=84 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=85 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=86 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=87 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=88 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=89 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=90 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=91 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=92 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=93 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=94 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=95 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=96 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=97 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=98 tscore=0.6169354838709677 vscore=0.5882352941176471\n",
      "epoch=99 tscore=0.6169354838709677 vscore=0.5882352941176471\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6hBDX5I6xNCXpA75/1FWuolWofHyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aaf3ba4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_lr.train(*data.get_train(), percentage=0.8, std=False, pca=0, threshold_unbalanced=0.6, epochs=100,\n",
    "            penalty=\"l2\", dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "            class_weight=None,  solver=\"newton-cg\", max_iter=100, multi_class=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAD8CAYAAABtsU60AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aaf273e898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best is MLP interface with score 0.83\n"
     ]
    }
   ],
   "source": [
    "test_sup(*data.get_valid(), my_lr, my_MLP, my_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
